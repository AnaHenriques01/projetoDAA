{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "# We will use the following models for our boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# We will use the following models for our ensemble learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import KBinsDiscretizer, MinMaxScaler\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "\n",
    "TRAINING_DATASET_SOURCE = '../datasets/training_data.csv'\n",
    "TEST_DATASET_SOURCE = '../datasets/test_data.csv'\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '5'\n",
    "\n",
    "categorical_to_numerical = {\n",
    "    'luminosity': {\n",
    "        'LOW_LIGHT': 0,\n",
    "        'LIGHT': 0,\n",
    "        'DARK': 1\n",
    "    },\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "'avg_rain': {\n",
    "    'Sem Chuva': 0,\n",
    "    'chuva fraca': 1,\n",
    "    'chuva moderada': 1,\n",
    "    'chuva forte': 1,\n",
    "}\"\"\"\n",
    "\n",
    "\n",
    "def convert_record_date(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_ = df.copy()\n",
    "\n",
    "    record_date = pd.DatetimeIndex(df_['record_date'])\n",
    "\n",
    "    df_.drop('record_date', axis=1, inplace=True)\n",
    "\n",
    "    df_['hour'] = record_date.hour\n",
    "    df_['day'] = record_date.day\n",
    "    df_['month'] = record_date.month\n",
    "    df_['weekday'] = record_date.weekday\n",
    "    df_['hour'] = record_date.hour\n",
    "\n",
    "    return df_\n",
    "\n",
    "\n",
    "def hour_of_the_day(hour):\n",
    "    if hour >= 20 or 0 <= hour <= 6:\n",
    "        return 0\n",
    "    elif 7 <= hour <= 19:\n",
    "        return 1\n",
    "\n",
    "    return 2\n",
    "\n",
    "\n",
    "def data_preprocessing(df):\n",
    "    dropped_columns = ['city_name', 'avg_precipitation', 'magnitude_of_delay', 'avg_rain']\n",
    "\n",
    "    prep_df = df.drop(dropped_columns, axis=1)\n",
    "    prep_df.drop_duplicates()\n",
    "    prep_df.replace(categorical_to_numerical, inplace=True)\n",
    "\n",
    "    prep_df = convert_record_date(prep_df)\n",
    "\n",
    "    num_affected_roads = []\n",
    "    for line in df['affected_roads']:\n",
    "        unique_roads = set(str(line).split(','))\n",
    "        valid_roads = [elem for elem in unique_roads if elem != '']\n",
    "        count = len(valid_roads)\n",
    "        num_affected_roads.append(count)\n",
    "    prep_df['num_affected_roads'] = num_affected_roads\n",
    "    prep_df.drop(columns=['affected_roads'],\n",
    "                 inplace=True)  # FIXME: Dropping the num_affected_roads for now\n",
    "\n",
    "    delay_in_minutes = prep_df['delay_in_seconds'].map(lambda seconds: seconds / 60)\n",
    "\n",
    "    prep_df.drop(columns=['delay_in_seconds'], inplace=True)\n",
    "    prep_df['delay_in_minutes'] = delay_in_minutes\n",
    "\n",
    "    est = KBinsDiscretizer(n_bins=2, strategy='kmeans', encode='ordinal')\n",
    "    prep_df['delay'] = est.fit_transform(prep_df[['delay_in_minutes']])\n",
    "    prep_df.drop(columns=['delay_in_minutes'], inplace=True) # FIXME: Dropping the deplay_in_minutes for now\n",
    "\n",
    "    prep_df[\"hour\"] = prep_df[\"hour\"].apply(hour_of_the_day)\n",
    "\n",
    "    numerical_features = [\n",
    "        'num_affected_roads', 'hour', 'day', 'month', 'weekday', 'avg_temperature', 'avg_atm_pressure',\n",
    "        'avg_wind_speed', 'avg_humidity'\n",
    "    ]\n",
    "    #prep_df[numerical_features] = MinMaxScaler().fit_transform(prep_df[numerical_features])\n",
    "\n",
    "    return prep_df\n",
    "\n",
    "\n",
    "def data_splitting(df):\n",
    "    X = data_preprocessing(df.drop('incidents', axis=1))\n",
    "    y = df['incidents']\n",
    "\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "def pre_data_preparation(train: pd.DataFrame) -> pd.DataFrame:\n",
    "    #print(train['incidents'].value_counts())\n",
    "\n",
    "    incidents_count = train['incidents'].value_counts()\n",
    "\n",
    "    max_count = incidents_count.max()\n",
    "    #print('Max value count:', max_count)\n",
    "\n",
    "    df_classes = []\n",
    "    for category, counts in zip(incidents_count.index, incidents_count):\n",
    "        df_classes.append(train[train['incidents'] == category])\n",
    "\n",
    "    df_classes_over = []\n",
    "\n",
    "    for category in df_classes:\n",
    "        df_classes_over.append(category.sample(max_count, replace=True, random_state=42))\n",
    "\n",
    "    df_test_over = pd.concat(df_classes_over, axis=0)\n",
    "\n",
    "    #print(df_test_over['incidents'].value_counts())\n",
    "\n",
    "    return df_test_over\n",
    "\n",
    "\n",
    "# noinspection PyPep8Naming\n",
    "def make_submission(submission_X: pd.DataFrame, submission_model: GridSearchCV):\n",
    "    predictions = submission_model.predict(submission_X)\n",
    "    predictions_df = pd.DataFrame(predictions)\n",
    "    predictions_df.index += 1\n",
    "    predictions_df.to_csv(\"submission.csv\", header=['Incidents'], index_label='RowId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(X, y):\n",
    "    train_model = CatBoostClassifier(loss_function=\"MultiClass\", verbose=False)\n",
    "\n",
    "    grid = {\n",
    "        'learning_rate': [0.1],  #[0.1125, 0.125, 0.1375],\n",
    "        'depth': [10],\n",
    "        'l2_leaf_reg': [1],\n",
    "        'early_stopping_rounds': [10]  #[10, 20, 40],\n",
    "    }\n",
    "\n",
    "    grid_search_result = train_model.grid_search(grid, X, y, plot=True, cv=5)\n",
    "\n",
    "    params = grid_search_result['params']\n",
    "    cv_results = grid_search_result['cv_results']\n",
    "\n",
    "    print(\"Best Parameters:\", params)\n",
    "\n",
    "    #for v in [\"test-MultiClass-mean\", \"test-MultiClass-std\", \"train-MultiClass-mean\", \"train-MultiClass-std\"]:\n",
    "    #    print(f\"Cross-validation {v}:\", cv_results[v])\n",
    "\n",
    "    train_score = train_model.score(X, y)\n",
    "\n",
    "    print(\"[Train] Accuracy:\", train_score)\n",
    "\n",
    "    return train_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noinspection PyPep8Naming\n",
    "def model_evaluation(X_test: pd.DataFrame, y_test: pd.Series):  # -> float:\n",
    "    print(\"y_test Value counts:\", y_test.value_counts())\n",
    "\n",
    "    y_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    model_predictions = model.predict(X_test)\n",
    "    print(f'Plotting Confusion Matrix for CatBoost')\n",
    "\n",
    "    plt.figure()\n",
    "    cm = confusion_matrix(y_test, model_predictions)\n",
    "    # TP FP\n",
    "    # FN TN\n",
    "    disp = ConfusionMatrixDisplay(cm)\n",
    "\n",
    "    disp.plot(cmap='inferno')\n",
    "\n",
    "    plt.title(f'Confusion Matrix - CatBoost')\n",
    "    plt.show()\n",
    "\n",
    "    failed_predications = []\n",
    "\n",
    "    print(\"Failed predications:\")\n",
    "    for (model_pred, true_pred, (index, X_value)) in zip(model_predictions, y_test, X_test.iterrows()):\n",
    "        if model_pred[0] != true_pred:\n",
    "            #print(f\"[{index}]\", X_value, 'has been classified as', model_pred, 'and should be', true_pred)\n",
    "            failed_predications.append([*X_value, true_pred, model_pred[0]])\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    failed_predications_df = pd.DataFrame(failed_predications,\n",
    "                                          columns=[*X_test.columns, 'True Label', 'Predicated Label'])\n",
    "\n",
    "    failed_predications_df.to_csv('failed_predications.csv')\n",
    "\n",
    "    return accuracy_score(y_test, model_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAINING_DATASET_SOURCE)\n",
    "test_df = pd.read_csv(TEST_DATASET_SOURCE)\n",
    "\n",
    "train_df = pre_data_preparation(train_df)\n",
    "print('Data Preprocessing done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prep_test_df = data_preprocessing(test_df)\n",
    "print('Preprocessed submission dataset done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "train_X, test_X, train_y, test_y = data_splitting(train_df)\n",
    "print('Data splitting done')\n",
    "print('Data prepared for training')\n",
    "\n",
    "print('Data shapes:', train_X.shape, test_X.shape, train_y.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = model_training(train_X, train_y)\n",
    "print('Model Training done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_acc = model_evaluation(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f'Making submission for CatBoost with test accuracy of {test_acc}')\n",
    "make_submission(prep_test_df, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ddb1a984dc606e8a9c0ef42c41531599b55da58846aaf6b0703a14cafee0a970"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
