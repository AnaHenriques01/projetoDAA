{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Implementação do Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "TRAINING_DATASET_SOURCE = '../training_data.csv'  # Since we are one directory up, we should go down one directory to import the datasets\n",
    "TEST_DATASET_SOURCE = '../test_data.csv'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(TRAINING_DATASET_SOURCE)\n",
    "test_df = pd.read_csv(TEST_DATASET_SOURCE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Definição dos dados de teste e de treino"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 13) (1206, 12)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, test_df.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "None         2028\nHigh         1073\nLow           718\nVery_High     603\nMedium        578\nName: incidents, dtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['incidents'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value count: 2028\n",
      "None         2028\n",
      "High         2028\n",
      "Low          2028\n",
      "Very_High    2028\n",
      "Medium       2028\n",
      "Name: incidents, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#count_class0, count_class1, count_class2, count_class3, count_class4 = train_df['incidents'].value_counts().to_frame()\n",
    "\n",
    "incidents_count = train_df['incidents'].value_counts()\n",
    "\n",
    "max_count = incidents_count.max()\n",
    "\n",
    "print('Max value count:', max_count)\n",
    "\n",
    "df_classes = []\n",
    "for category, counts in zip(incidents_count.index, incidents_count):\n",
    "    #print(category, counts)\n",
    "    df_classes.append(train_df[train_df['incidents'] == category])\n",
    "\n",
    "df_classes_over = []\n",
    "\n",
    "for category in df_classes:\n",
    "    df_classes_over.append(category.sample(max_count, replace=True))\n",
    "\n",
    "df_test_over = pd.concat(df_classes_over, axis=0)\n",
    "\n",
    "print(df_test_over['incidents'].value_counts())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dropped_columns = ['city_name', 'avg_precipitation', 'magnitude_of_delay', 'record_date', 'affected_roads']\n",
    "\n",
    "X = df_test_over.drop([*dropped_columns, 'incidents'], axis=1)\n",
    "y = df_test_over['incidents']\n",
    "\n",
    "all_features = X.columns.tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "      delay_in_seconds luminosity  avg_temperature  avg_atm_pressure  \\\n1931                 0       DARK              8.0            1016.0   \n2869                 0      LIGHT             22.0            1019.0   \n4801                 0      LIGHT             13.0            1023.0   \n4139                 0       DARK             16.0            1020.0   \n1625                 0      LIGHT             16.0            1015.0   \n...                ...        ...              ...               ...   \n4860               210      LIGHT              6.0            1026.0   \n1406                 0       DARK             13.0            1018.0   \n2782                 0      LIGHT             12.0            1025.0   \n3640                 0       DARK             11.0            1024.0   \n218                981      LIGHT             29.0            1018.0   \n\n      avg_humidity  avg_wind_speed   avg_rain  \n1931          76.0             1.0  Sem Chuva  \n2869          69.0             0.0  Sem Chuva  \n4801          42.0             2.0  Sem Chuva  \n4139          80.0             1.0  Sem Chuva  \n1625          93.0             1.0  Sem Chuva  \n...            ...             ...        ...  \n4860          94.0             1.0  Sem Chuva  \n1406          92.0             0.0  Sem Chuva  \n2782          65.0             2.0  Sem Chuva  \n3640          68.0             2.0  Sem Chuva  \n218           45.0             2.0  Sem Chuva  \n\n[10140 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>delay_in_seconds</th>\n      <th>luminosity</th>\n      <th>avg_temperature</th>\n      <th>avg_atm_pressure</th>\n      <th>avg_humidity</th>\n      <th>avg_wind_speed</th>\n      <th>avg_rain</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1931</th>\n      <td>0</td>\n      <td>DARK</td>\n      <td>8.0</td>\n      <td>1016.0</td>\n      <td>76.0</td>\n      <td>1.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>2869</th>\n      <td>0</td>\n      <td>LIGHT</td>\n      <td>22.0</td>\n      <td>1019.0</td>\n      <td>69.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>4801</th>\n      <td>0</td>\n      <td>LIGHT</td>\n      <td>13.0</td>\n      <td>1023.0</td>\n      <td>42.0</td>\n      <td>2.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>4139</th>\n      <td>0</td>\n      <td>DARK</td>\n      <td>16.0</td>\n      <td>1020.0</td>\n      <td>80.0</td>\n      <td>1.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>1625</th>\n      <td>0</td>\n      <td>LIGHT</td>\n      <td>16.0</td>\n      <td>1015.0</td>\n      <td>93.0</td>\n      <td>1.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4860</th>\n      <td>210</td>\n      <td>LIGHT</td>\n      <td>6.0</td>\n      <td>1026.0</td>\n      <td>94.0</td>\n      <td>1.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>1406</th>\n      <td>0</td>\n      <td>DARK</td>\n      <td>13.0</td>\n      <td>1018.0</td>\n      <td>92.0</td>\n      <td>0.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>2782</th>\n      <td>0</td>\n      <td>LIGHT</td>\n      <td>12.0</td>\n      <td>1025.0</td>\n      <td>65.0</td>\n      <td>2.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>3640</th>\n      <td>0</td>\n      <td>DARK</td>\n      <td>11.0</td>\n      <td>1024.0</td>\n      <td>68.0</td>\n      <td>2.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n    <tr>\n      <th>218</th>\n      <td>981</td>\n      <td>LIGHT</td>\n      <td>29.0</td>\n      <td>1018.0</td>\n      <td>45.0</td>\n      <td>2.0</td>\n      <td>Sem Chuva</td>\n    </tr>\n  </tbody>\n</table>\n<p>10140 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "numerical_features = [column for column, dtype in zip(X.columns, X.dtypes)\n",
    "                      if dtype.kind in ['i', 'f']]\n",
    "\n",
    "categorical_features = [column for column, dtype in zip(X.columns, X.dtypes)\n",
    "                        if dtype.kind not in ['i', 'f']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (make_pipeline(\n",
    "        SimpleImputer(strategy='median'),\n",
    "        MinMaxScaler()\n",
    "    ), numerical_features),\n",
    "\n",
    "    (make_pipeline(\n",
    "        SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "        OneHotEncoder(categories='auto', handle_unknown='ignore')\n",
    "\n",
    "    ), categorical_features)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold, f_classif\n",
    "\n",
    "preprocessor_best = make_pipeline(preprocessor, VarianceThreshold(), SelectKBest(f_classif, k='all'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF_Model = make_pipeline(preprocessor_best, RandomForestClassifier(n_estimators=100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9978867286559594"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_Model.fit(X_train, y_train)\n",
    "RF_Model.score(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9293228139381986"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_Model.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter Tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start=10, stop=20, num=3)]\n",
    "\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "max_depth = [2, 6]\n",
    "\n",
    "min_samples_split = [2, 5]\n",
    "\n",
    "min_samples_leaf = [1, 2]\n",
    "\n",
    "bootstrap = [True, False]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "{'randomforestclassifier__n_estimators': [10, 15, 20],\n 'randomforestclassifier__max_features': ['auto', 'sqrt'],\n 'randomforestclassifier__max_depth': [2, 6],\n 'randomforestclassifier__min_samples_split': [2, 5],\n 'randomforestclassifier__min_samples_leaf': [1, 2],\n 'randomforestclassifier__bootstrap': [True, False]}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': n_estimators,\n",
    "    'randomforestclassifier__max_features': max_features,\n",
    "    'randomforestclassifier__max_depth': max_depth,\n",
    "    'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "    'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "    'randomforestclassifier__bootstrap': bootstrap,\n",
    "}\n",
    "\n",
    "param_grid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rf_RandomGrid = RandomizedSearchCV(estimator=RF_Model, param_distributions=param_grid, cv=3, verbose=1, n_jobs=-1,\n",
    "                                   n_iter=5, scoring='f1')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 15 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n15 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\gonca\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\gonca\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in fit\n    fit_params_steps = self._check_fit_params(**fit_params)\n  File \"C:\\Users\\gonca\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\pipeline.py\", line 300, in _check_fit_params\n    raise ValueError(\nValueError: Pipeline.fit does not accept the average parameter. You can pass parameters to specific steps of your pipeline using the stepname__parameter format, e.g. `Pipeline.fit(X, y, logisticregression__sample_weight=sample_weight)`.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[1;32m<timed eval>:1\u001B[0m\n",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    869\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    870\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    871\u001B[0m     )\n\u001B[0;32m    873\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 875\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    878\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    879\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1753\u001B[0m, in \u001B[0;36mRandomizedSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1751\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1752\u001B[0m     \u001B[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1753\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1754\u001B[0m \u001B[43m        \u001B[49m\u001B[43mParameterSampler\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1755\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_distributions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\n\u001B[0;32m   1756\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1757\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    845\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m!=\u001B[39m n_candidates \u001B[38;5;241m*\u001B[39m n_splits:\n\u001B[0;32m    846\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    847\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcv.split and cv.get_n_splits returned \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    848\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minconsistent results. Expected \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    849\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplits, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(n_splits, \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m n_candidates)\n\u001B[0;32m    850\u001B[0m     )\n\u001B[1;32m--> 852\u001B[0m \u001B[43m_warn_or_raise_about_fit_failures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    854\u001B[0m \u001B[38;5;66;03m# For callable self.scoring, the return type is only know after\u001B[39;00m\n\u001B[0;32m    855\u001B[0m \u001B[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001B[39;00m\n\u001B[0;32m    856\u001B[0m \u001B[38;5;66;03m# can now be inserted with the correct key. The type checking\u001B[39;00m\n\u001B[0;32m    857\u001B[0m \u001B[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001B[39;00m\n\u001B[0;32m    858\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring):\n",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001B[0m, in \u001B[0;36m_warn_or_raise_about_fit_failures\u001B[1;34m(results, error_score)\u001B[0m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_failed_fits \u001B[38;5;241m==\u001B[39m num_fits:\n\u001B[0;32m    361\u001B[0m     all_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    362\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAll the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    363\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt is very likely that your model is misconfigured.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    364\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can try to debug the error by setting error_score=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    365\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    366\u001B[0m     )\n\u001B[1;32m--> 367\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(all_fits_failed_message)\n\u001B[0;32m    369\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    370\u001B[0m     some_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    371\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mnum_failed_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed out of a total of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    372\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe score on these train-test partitions for these parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    376\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    377\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: \nAll the 15 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n15 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\gonca\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\gonca\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\pipeline.py\", line 377, in fit\n    fit_params_steps = self._check_fit_params(**fit_params)\n  File \"C:\\Users\\gonca\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\pipeline.py\", line 300, in _check_fit_params\n    raise ValueError(\nValueError: Pipeline.fit does not accept the average parameter. You can pass parameters to specific steps of your pipeline using the stepname__parameter format, e.g. `Pipeline.fit(X, y, logisticregression__sample_weight=sample_weight)`.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_RandomGrid.fit(X_train, y_train, average='weighted')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomizedSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [34], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m rf_RandomGrid\u001B[38;5;241m.\u001B[39mscore(X_train, y_train)\n",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\model_selection\\_search.py:437\u001B[0m, in \u001B[0;36mBaseSearchCV.score\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    414\u001B[0m \u001B[38;5;124;03m\"\"\"Return the score on the given data, if the estimator has been refit.\u001B[39;00m\n\u001B[0;32m    415\u001B[0m \n\u001B[0;32m    416\u001B[0m \u001B[38;5;124;03mThis uses the score defined by ``scoring`` where provided, and the\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    434\u001B[0m \u001B[38;5;124;03m    ``best_estimator_.score`` method otherwise.\u001B[39;00m\n\u001B[0;32m    435\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    436\u001B[0m _check_refit(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscore\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 437\u001B[0m \u001B[43mcheck_is_fitted\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    438\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscorer_ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    439\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    440\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo score function explicitly defined, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    441\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mand the estimator doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt provide one \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    442\u001B[0m         \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_estimator_\n\u001B[0;32m    443\u001B[0m     )\n",
      "File \u001B[1;32m~\\.conda\\envs\\DAA\\lib\\site-packages\\sklearn\\utils\\validation.py:1345\u001B[0m, in \u001B[0;36mcheck_is_fitted\u001B[1;34m(estimator, attributes, msg, all_or_any)\u001B[0m\n\u001B[0;32m   1340\u001B[0m     fitted \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   1341\u001B[0m         v \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mvars\u001B[39m(estimator) \u001B[38;5;28;01mif\u001B[39;00m v\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m v\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1342\u001B[0m     ]\n\u001B[0;32m   1344\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fitted:\n\u001B[1;32m-> 1345\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m NotFittedError(msg \u001B[38;5;241m%\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(estimator)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m})\n",
      "\u001B[1;31mNotFittedError\u001B[0m: This RandomizedSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "rf_RandomGrid.score(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
