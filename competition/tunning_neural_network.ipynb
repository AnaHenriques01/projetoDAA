{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "from tensorflow.python.keras.losses import SparseCategoricalCrossentropy\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(tf.__version__)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Carregamento de dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "TRAINING_DATASET_SOURCE = 'training_data.csv'\n",
    "TEST_DATASET_SOURCE = 'test_data.csv'\n",
    "\n",
    "train_df = pd.read_csv(TRAINING_DATASET_SOURCE)\n",
    "test_df = pd.read_csv(TEST_DATASET_SOURCE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SEED utilizada"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "SEED = 101"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparação dos dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "categorical_to_numerical = {\n",
    "    'avg_rain': {\n",
    "        'Sem Chuva': 0,\n",
    "        'chuva fraca': 1,\n",
    "        'chuva moderada': 2,\n",
    "        'chuva forte': 3\n",
    "    },\n",
    "    'luminosity': {\n",
    "        'LOW_LIGHT': 0,\n",
    "        'LIGHT': 1,\n",
    "        'DARK': 2,\n",
    "    }\n",
    "}\n",
    "\n",
    "incidents_to_numerical = {\n",
    "    'incidents': {\n",
    "        'None': 0,\n",
    "        'Low': 1,\n",
    "        'Medium': 2,\n",
    "        'High': 3,\n",
    "        'Very_High': 4,\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def neural_network_data_preparation(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    dropped_columns = ['city_name', 'magnitude_of_delay', 'avg_precipitation']\n",
    "\n",
    "    prep_df = df.drop(dropped_columns, axis=1)\n",
    "\n",
    "    ### Extrair a hora e dia da semana da feature 'record_date'\n",
    "    record_date = pd.DatetimeIndex(prep_df['record_date'])\n",
    "\n",
    "    prep_df['record_date_hour'] = record_date.hour\n",
    "    prep_df['record_date_day'] = record_date.day\n",
    "    prep_df['record_date_month'] = record_date.month\n",
    "    prep_df['record_date_weekday'] = record_date.weekday\n",
    "\n",
    "    prep_df.drop(columns=['record_date'], inplace=True)\n",
    "\n",
    "    ### Quantificar a feature 'affected_roads' para o número único de estradas afetadas\n",
    "    road_quantity = []\n",
    "    for line in prep_df['affected_roads']:\n",
    "        res = set(str(line).split(','))\n",
    "        res2 = [elem for elem in res if elem != '']\n",
    "        count = len(res2)\n",
    "        road_quantity.append(count)\n",
    "\n",
    "    prep_df['affected_roads'] = road_quantity\n",
    "\n",
    "    prep_df.replace(categorical_to_numerical, inplace=True)\n",
    "\n",
    "    ### Target\n",
    "    if 'incidents' in prep_df.columns:\n",
    "        prep_df.replace(incidents_to_numerical, inplace=True)\n",
    "\n",
    "    return prep_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X = neural_network_data_preparation(train_df)\n",
    "y = X['incidents']\n",
    "\n",
    "X.drop(columns=['incidents'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "X_scaled = pd.DataFrame(scaler_X.transform(X[X.columns]), columns=X.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Construção da estrutura da rede neuronal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "!pip install -q -U keras-tuner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    # Create a sequential model (with three layers - last one is the output)\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    input_hp_units = hp.Int('units', min_value=5, max_value=200, step=5)\n",
    "\n",
    "    model.add(Dense(input_hp_units, input_dim=12, activation='relu'))\n",
    "\n",
    "    hp_units = hp.Int('units', min_value=5, max_value=200, step=5)\n",
    "\n",
    "    hp_activation = hp.Choice(\"activation\", [\"relu\", \"tanh\", 'sigmoid'])\n",
    "\n",
    "    model.add(Dense(hp_units, activation=hp_activation))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    # Model compilation\n",
    "    model.compile(loss=SparseCategoricalCrossentropy(), optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"trials\",\n",
    "    project_name=\"competition\",\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 00m 04s]\n",
      "accuracy: 0.5038750171661377\n",
      "\n",
      "Best accuracy So Far: 0.5832499861717224\n",
      "Total elapsed time: 00h 00m 31s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 125 and the optimal learning rate for the optimizer\n",
      "is 0.0001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(X, y, epochs=500, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 14.4710 - accuracy: 0.4500 - val_loss: 2.1900 - val_accuracy: 0.5500\n",
      "Epoch 2/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.9765 - accuracy: 0.5260 - val_loss: 1.8644 - val_accuracy: 0.5570\n",
      "Epoch 3/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.6485 - accuracy: 0.5393 - val_loss: 1.7964 - val_accuracy: 0.5590\n",
      "Epoch 4/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.5566 - accuracy: 0.5315 - val_loss: 1.4571 - val_accuracy: 0.5660\n",
      "Epoch 5/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.4021 - accuracy: 0.5595 - val_loss: 1.2927 - val_accuracy: 0.5760\n",
      "Epoch 6/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3314 - accuracy: 0.5713 - val_loss: 1.3746 - val_accuracy: 0.5380\n",
      "Epoch 7/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3599 - accuracy: 0.5455 - val_loss: 1.6464 - val_accuracy: 0.5680\n",
      "Epoch 8/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.4012 - accuracy: 0.5665 - val_loss: 1.8118 - val_accuracy: 0.3800\n",
      "Epoch 9/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2399 - accuracy: 0.5715 - val_loss: 1.2423 - val_accuracy: 0.5630\n",
      "Epoch 10/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2567 - accuracy: 0.5673 - val_loss: 1.3462 - val_accuracy: 0.5750\n",
      "Epoch 11/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2434 - accuracy: 0.5780 - val_loss: 1.4563 - val_accuracy: 0.5760\n",
      "Epoch 12/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2945 - accuracy: 0.5683 - val_loss: 1.3771 - val_accuracy: 0.5250\n",
      "Epoch 13/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2330 - accuracy: 0.5638 - val_loss: 1.2636 - val_accuracy: 0.5660\n",
      "Epoch 14/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2938 - accuracy: 0.5715 - val_loss: 1.3622 - val_accuracy: 0.5820\n",
      "Epoch 15/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2179 - accuracy: 0.5857 - val_loss: 1.1917 - val_accuracy: 0.5700\n",
      "Epoch 16/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1313 - accuracy: 0.5855 - val_loss: 1.5022 - val_accuracy: 0.5570\n",
      "Epoch 17/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2325 - accuracy: 0.5803 - val_loss: 1.4916 - val_accuracy: 0.5540\n",
      "Epoch 18/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1718 - accuracy: 0.5860 - val_loss: 1.2095 - val_accuracy: 0.5780\n",
      "Epoch 19/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1895 - accuracy: 0.5897 - val_loss: 1.2432 - val_accuracy: 0.5290\n",
      "Epoch 20/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1325 - accuracy: 0.5813 - val_loss: 1.5135 - val_accuracy: 0.5590\n",
      "Epoch 21/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1189 - accuracy: 0.5925 - val_loss: 1.1111 - val_accuracy: 0.5710\n",
      "Epoch 22/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1270 - accuracy: 0.5825 - val_loss: 1.1624 - val_accuracy: 0.5870\n",
      "Epoch 23/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0837 - accuracy: 0.5903 - val_loss: 1.1933 - val_accuracy: 0.5630\n",
      "Epoch 24/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1370 - accuracy: 0.5932 - val_loss: 1.2339 - val_accuracy: 0.5790\n",
      "Epoch 25/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1339 - accuracy: 0.5940 - val_loss: 1.5821 - val_accuracy: 0.5830\n",
      "Epoch 26/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1652 - accuracy: 0.5910 - val_loss: 1.2358 - val_accuracy: 0.5620\n",
      "Epoch 27/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0821 - accuracy: 0.5935 - val_loss: 1.2307 - val_accuracy: 0.5400\n",
      "Epoch 28/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1420 - accuracy: 0.5897 - val_loss: 1.1460 - val_accuracy: 0.5560\n",
      "Epoch 29/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0297 - accuracy: 0.6050 - val_loss: 1.0224 - val_accuracy: 0.6150\n",
      "Epoch 30/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1104 - accuracy: 0.5957 - val_loss: 1.0970 - val_accuracy: 0.6110\n",
      "Epoch 31/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1238 - accuracy: 0.5980 - val_loss: 1.0868 - val_accuracy: 0.5830\n",
      "Epoch 32/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0413 - accuracy: 0.6055 - val_loss: 0.9890 - val_accuracy: 0.6140\n",
      "Epoch 33/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0568 - accuracy: 0.6058 - val_loss: 1.0962 - val_accuracy: 0.5980\n",
      "Epoch 34/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0762 - accuracy: 0.6100 - val_loss: 1.2446 - val_accuracy: 0.5860\n",
      "Epoch 35/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0920 - accuracy: 0.6060 - val_loss: 1.1748 - val_accuracy: 0.6020\n",
      "Epoch 36/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0320 - accuracy: 0.6205 - val_loss: 1.0421 - val_accuracy: 0.5990\n",
      "Epoch 37/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0393 - accuracy: 0.6100 - val_loss: 0.9683 - val_accuracy: 0.6170\n",
      "Epoch 38/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0115 - accuracy: 0.6030 - val_loss: 1.3135 - val_accuracy: 0.6230\n",
      "Epoch 39/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0997 - accuracy: 0.6095 - val_loss: 1.0766 - val_accuracy: 0.6290\n",
      "Epoch 40/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0980 - accuracy: 0.6135 - val_loss: 1.0212 - val_accuracy: 0.6060\n",
      "Epoch 41/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0615 - accuracy: 0.6177 - val_loss: 1.1328 - val_accuracy: 0.5700\n",
      "Epoch 42/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0230 - accuracy: 0.6250 - val_loss: 1.3332 - val_accuracy: 0.5530\n",
      "Epoch 43/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0355 - accuracy: 0.6083 - val_loss: 0.9788 - val_accuracy: 0.6150\n",
      "Epoch 44/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0693 - accuracy: 0.6162 - val_loss: 1.1333 - val_accuracy: 0.6030\n",
      "Epoch 45/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0225 - accuracy: 0.6225 - val_loss: 1.1477 - val_accuracy: 0.6070\n",
      "Epoch 46/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0119 - accuracy: 0.6248 - val_loss: 1.0816 - val_accuracy: 0.5800\n",
      "Epoch 47/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9962 - accuracy: 0.6270 - val_loss: 0.9684 - val_accuracy: 0.6200\n",
      "Epoch 48/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0599 - accuracy: 0.6105 - val_loss: 1.1408 - val_accuracy: 0.5950\n",
      "Epoch 49/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0216 - accuracy: 0.6345 - val_loss: 0.9653 - val_accuracy: 0.6240\n",
      "Epoch 50/50\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0265 - accuracy: 0.6208 - val_loss: 1.0169 - val_accuracy: 0.6050\n",
      "Best epoch: 39\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X, y, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/39\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 16.7546 - accuracy: 0.3685 - val_loss: 2.6389 - val_accuracy: 0.5000\n",
      "Epoch 2/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 2.0260 - accuracy: 0.4695 - val_loss: 1.8231 - val_accuracy: 0.4610\n",
      "Epoch 3/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.8682 - accuracy: 0.4753 - val_loss: 1.8711 - val_accuracy: 0.4180\n",
      "Epoch 4/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.6993 - accuracy: 0.4950 - val_loss: 1.6981 - val_accuracy: 0.5010\n",
      "Epoch 5/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.5689 - accuracy: 0.5117 - val_loss: 1.7308 - val_accuracy: 0.5460\n",
      "Epoch 6/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.5108 - accuracy: 0.5343 - val_loss: 1.4812 - val_accuracy: 0.5580\n",
      "Epoch 7/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.4075 - accuracy: 0.5387 - val_loss: 1.3997 - val_accuracy: 0.5660\n",
      "Epoch 8/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3747 - accuracy: 0.5573 - val_loss: 1.4215 - val_accuracy: 0.5770\n",
      "Epoch 9/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3934 - accuracy: 0.5510 - val_loss: 1.3499 - val_accuracy: 0.5590\n",
      "Epoch 10/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2965 - accuracy: 0.5600 - val_loss: 1.3525 - val_accuracy: 0.5790\n",
      "Epoch 11/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2741 - accuracy: 0.5633 - val_loss: 1.2939 - val_accuracy: 0.5620\n",
      "Epoch 12/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2745 - accuracy: 0.5660 - val_loss: 1.2830 - val_accuracy: 0.5740\n",
      "Epoch 13/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2985 - accuracy: 0.5660 - val_loss: 1.3265 - val_accuracy: 0.5710\n",
      "Epoch 14/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2045 - accuracy: 0.5778 - val_loss: 1.1155 - val_accuracy: 0.5830\n",
      "Epoch 15/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1607 - accuracy: 0.5903 - val_loss: 1.0781 - val_accuracy: 0.6170\n",
      "Epoch 16/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1856 - accuracy: 0.5775 - val_loss: 1.1113 - val_accuracy: 0.5810\n",
      "Epoch 17/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2158 - accuracy: 0.5748 - val_loss: 1.2186 - val_accuracy: 0.5890\n",
      "Epoch 18/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1771 - accuracy: 0.5842 - val_loss: 1.1583 - val_accuracy: 0.6020\n",
      "Epoch 19/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1836 - accuracy: 0.5803 - val_loss: 1.3291 - val_accuracy: 0.5430\n",
      "Epoch 20/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1726 - accuracy: 0.5835 - val_loss: 1.0920 - val_accuracy: 0.6100\n",
      "Epoch 21/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2926 - accuracy: 0.5723 - val_loss: 1.1848 - val_accuracy: 0.5810\n",
      "Epoch 22/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1498 - accuracy: 0.5918 - val_loss: 1.3854 - val_accuracy: 0.5530\n",
      "Epoch 23/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0926 - accuracy: 0.5968 - val_loss: 1.2134 - val_accuracy: 0.5860\n",
      "Epoch 24/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1373 - accuracy: 0.5880 - val_loss: 1.1726 - val_accuracy: 0.5700\n",
      "Epoch 25/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1209 - accuracy: 0.5957 - val_loss: 1.2050 - val_accuracy: 0.5820\n",
      "Epoch 26/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1630 - accuracy: 0.5803 - val_loss: 1.0453 - val_accuracy: 0.5900\n",
      "Epoch 27/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1112 - accuracy: 0.5867 - val_loss: 1.6813 - val_accuracy: 0.5610\n",
      "Epoch 28/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1093 - accuracy: 0.6000 - val_loss: 1.1969 - val_accuracy: 0.6020\n",
      "Epoch 29/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2866 - accuracy: 0.5922 - val_loss: 1.1132 - val_accuracy: 0.5860\n",
      "Epoch 30/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1559 - accuracy: 0.5875 - val_loss: 1.1793 - val_accuracy: 0.5920\n",
      "Epoch 31/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0716 - accuracy: 0.6012 - val_loss: 1.0781 - val_accuracy: 0.6250\n",
      "Epoch 32/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1303 - accuracy: 0.5880 - val_loss: 1.2106 - val_accuracy: 0.5550\n",
      "Epoch 33/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1023 - accuracy: 0.6033 - val_loss: 1.0616 - val_accuracy: 0.6180\n",
      "Epoch 34/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2870 - accuracy: 0.5895 - val_loss: 1.1503 - val_accuracy: 0.5650\n",
      "Epoch 35/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0818 - accuracy: 0.5985 - val_loss: 1.1461 - val_accuracy: 0.5160\n",
      "Epoch 36/39\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 1.1286 - accuracy: 0.5995 - val_loss: 1.0368 - val_accuracy: 0.6280\n",
      "Epoch 37/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0569 - accuracy: 0.6120 - val_loss: 1.0577 - val_accuracy: 0.5990\n",
      "Epoch 38/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1513 - accuracy: 0.5845 - val_loss: 1.2565 - val_accuracy: 0.5510\n",
      "Epoch 39/39\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1293 - accuracy: 0.6043 - val_loss: 1.0239 - val_accuracy: 0.6020\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x219f5cb8460>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(X, y, epochs=best_epoch, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 738us/step - loss: 0.9730 - accuracy: 0.6164\n",
      "[test loss, test accuracy]: [0.9730112552642822, 0.6164000034332275]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(X, y)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-------\n",
    "-------\n",
    "-------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.4791 - accuracy: 0.3862 - val_loss: 1.4063 - val_accuracy: 0.4130\n",
      "Epoch 2/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3778 - accuracy: 0.4150 - val_loss: 1.3494 - val_accuracy: 0.4360\n",
      "Epoch 3/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.3274 - accuracy: 0.4487 - val_loss: 1.3064 - val_accuracy: 0.5010\n",
      "Epoch 4/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2864 - accuracy: 0.4947 - val_loss: 1.2688 - val_accuracy: 0.5140\n",
      "Epoch 5/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2515 - accuracy: 0.5165 - val_loss: 1.2388 - val_accuracy: 0.5320\n",
      "Epoch 6/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.2212 - accuracy: 0.5272 - val_loss: 1.2115 - val_accuracy: 0.5410\n",
      "Epoch 7/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1952 - accuracy: 0.5375 - val_loss: 1.1873 - val_accuracy: 0.5400\n",
      "Epoch 8/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1734 - accuracy: 0.5480 - val_loss: 1.1673 - val_accuracy: 0.5590\n",
      "Epoch 9/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1525 - accuracy: 0.5573 - val_loss: 1.1487 - val_accuracy: 0.5680\n",
      "Epoch 10/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1350 - accuracy: 0.5667 - val_loss: 1.1316 - val_accuracy: 0.5790\n",
      "Epoch 11/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1184 - accuracy: 0.5790 - val_loss: 1.1170 - val_accuracy: 0.5850\n",
      "Epoch 12/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.1028 - accuracy: 0.5872 - val_loss: 1.1034 - val_accuracy: 0.5980\n",
      "Epoch 13/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0889 - accuracy: 0.5940 - val_loss: 1.0914 - val_accuracy: 0.5970\n",
      "Epoch 14/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0767 - accuracy: 0.6015 - val_loss: 1.0790 - val_accuracy: 0.6090\n",
      "Epoch 15/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0653 - accuracy: 0.6097 - val_loss: 1.0677 - val_accuracy: 0.6160\n",
      "Epoch 16/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0549 - accuracy: 0.6160 - val_loss: 1.0581 - val_accuracy: 0.6150\n",
      "Epoch 17/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0449 - accuracy: 0.6210 - val_loss: 1.0503 - val_accuracy: 0.6170\n",
      "Epoch 18/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0357 - accuracy: 0.6255 - val_loss: 1.0402 - val_accuracy: 0.6290\n",
      "Epoch 19/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0278 - accuracy: 0.6290 - val_loss: 1.0312 - val_accuracy: 0.6340\n",
      "Epoch 20/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0188 - accuracy: 0.6370 - val_loss: 1.0240 - val_accuracy: 0.6370\n",
      "Epoch 21/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0113 - accuracy: 0.6398 - val_loss: 1.0174 - val_accuracy: 0.6370\n",
      "Epoch 22/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 1.0044 - accuracy: 0.6407 - val_loss: 1.0093 - val_accuracy: 0.6410\n",
      "Epoch 23/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9976 - accuracy: 0.6495 - val_loss: 1.0026 - val_accuracy: 0.6420\n",
      "Epoch 24/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9911 - accuracy: 0.6480 - val_loss: 0.9954 - val_accuracy: 0.6510\n",
      "Epoch 25/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9853 - accuracy: 0.6532 - val_loss: 0.9937 - val_accuracy: 0.6390\n",
      "Epoch 26/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9797 - accuracy: 0.6532 - val_loss: 0.9849 - val_accuracy: 0.6490\n",
      "Epoch 27/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9743 - accuracy: 0.6530 - val_loss: 0.9801 - val_accuracy: 0.6510\n",
      "Epoch 28/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9697 - accuracy: 0.6547 - val_loss: 0.9777 - val_accuracy: 0.6460\n",
      "Epoch 29/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9660 - accuracy: 0.6545 - val_loss: 0.9722 - val_accuracy: 0.6490\n",
      "Epoch 30/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9608 - accuracy: 0.6528 - val_loss: 0.9671 - val_accuracy: 0.6570\n",
      "Epoch 31/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9580 - accuracy: 0.6578 - val_loss: 0.9617 - val_accuracy: 0.6500\n",
      "Epoch 32/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9528 - accuracy: 0.6595 - val_loss: 0.9640 - val_accuracy: 0.6460\n",
      "Epoch 33/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9499 - accuracy: 0.6562 - val_loss: 0.9559 - val_accuracy: 0.6520\n",
      "Epoch 34/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9460 - accuracy: 0.6615 - val_loss: 0.9511 - val_accuracy: 0.6520\n",
      "Epoch 35/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9429 - accuracy: 0.6600 - val_loss: 0.9501 - val_accuracy: 0.6510\n",
      "Epoch 36/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9397 - accuracy: 0.6618 - val_loss: 0.9492 - val_accuracy: 0.6510\n",
      "Epoch 37/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9357 - accuracy: 0.6628 - val_loss: 0.9429 - val_accuracy: 0.6550\n",
      "Epoch 38/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9325 - accuracy: 0.6607 - val_loss: 0.9399 - val_accuracy: 0.6540\n",
      "Epoch 39/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9296 - accuracy: 0.6622 - val_loss: 0.9378 - val_accuracy: 0.6530\n",
      "Epoch 40/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9261 - accuracy: 0.6615 - val_loss: 0.9360 - val_accuracy: 0.6530\n",
      "Epoch 41/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9235 - accuracy: 0.6660 - val_loss: 0.9316 - val_accuracy: 0.6540\n",
      "Epoch 42/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9202 - accuracy: 0.6637 - val_loss: 0.9286 - val_accuracy: 0.6540\n",
      "Epoch 43/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9184 - accuracy: 0.6655 - val_loss: 0.9257 - val_accuracy: 0.6530\n",
      "Epoch 44/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9147 - accuracy: 0.6645 - val_loss: 0.9237 - val_accuracy: 0.6570\n",
      "Epoch 45/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9120 - accuracy: 0.6678 - val_loss: 0.9206 - val_accuracy: 0.6500\n",
      "Epoch 46/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9087 - accuracy: 0.6647 - val_loss: 0.9190 - val_accuracy: 0.6600\n",
      "Epoch 47/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9067 - accuracy: 0.6683 - val_loss: 0.9154 - val_accuracy: 0.6550\n",
      "Epoch 48/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9035 - accuracy: 0.6695 - val_loss: 0.9132 - val_accuracy: 0.6550\n",
      "Epoch 49/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.9011 - accuracy: 0.6665 - val_loss: 0.9096 - val_accuracy: 0.6620\n",
      "Epoch 50/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8988 - accuracy: 0.6697 - val_loss: 0.9109 - val_accuracy: 0.6610\n",
      "Epoch 51/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8963 - accuracy: 0.6680 - val_loss: 0.9092 - val_accuracy: 0.6650\n",
      "Epoch 52/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8938 - accuracy: 0.6697 - val_loss: 0.9028 - val_accuracy: 0.6630\n",
      "Epoch 53/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8920 - accuracy: 0.6740 - val_loss: 0.9026 - val_accuracy: 0.6600\n",
      "Epoch 54/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8884 - accuracy: 0.6727 - val_loss: 0.8995 - val_accuracy: 0.6650\n",
      "Epoch 55/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8865 - accuracy: 0.6760 - val_loss: 0.8972 - val_accuracy: 0.6580\n",
      "Epoch 56/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8838 - accuracy: 0.6725 - val_loss: 0.8962 - val_accuracy: 0.6630\n",
      "Epoch 57/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8811 - accuracy: 0.6747 - val_loss: 0.8924 - val_accuracy: 0.6570\n",
      "Epoch 58/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8781 - accuracy: 0.6752 - val_loss: 0.8928 - val_accuracy: 0.6610\n",
      "Epoch 59/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8761 - accuracy: 0.6715 - val_loss: 0.8883 - val_accuracy: 0.6680\n",
      "Epoch 60/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8728 - accuracy: 0.6743 - val_loss: 0.8890 - val_accuracy: 0.6710\n",
      "Epoch 61/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8722 - accuracy: 0.6765 - val_loss: 0.8852 - val_accuracy: 0.6680\n",
      "Epoch 62/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8682 - accuracy: 0.6812 - val_loss: 0.8838 - val_accuracy: 0.6610\n",
      "Epoch 63/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8657 - accuracy: 0.6768 - val_loss: 0.8801 - val_accuracy: 0.6760\n",
      "Epoch 64/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8634 - accuracy: 0.6808 - val_loss: 0.8779 - val_accuracy: 0.6750\n",
      "Epoch 65/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8607 - accuracy: 0.6842 - val_loss: 0.8812 - val_accuracy: 0.6630\n",
      "Epoch 66/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8588 - accuracy: 0.6848 - val_loss: 0.8771 - val_accuracy: 0.6640\n",
      "Epoch 67/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8563 - accuracy: 0.6820 - val_loss: 0.8726 - val_accuracy: 0.6810\n",
      "Epoch 68/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8553 - accuracy: 0.6877 - val_loss: 0.8729 - val_accuracy: 0.6650\n",
      "Epoch 69/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8509 - accuracy: 0.6877 - val_loss: 0.8691 - val_accuracy: 0.6770\n",
      "Epoch 70/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8488 - accuracy: 0.6850 - val_loss: 0.8658 - val_accuracy: 0.6790\n",
      "Epoch 71/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8466 - accuracy: 0.6875 - val_loss: 0.8658 - val_accuracy: 0.6710\n",
      "Epoch 72/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8447 - accuracy: 0.6845 - val_loss: 0.8648 - val_accuracy: 0.6730\n",
      "Epoch 73/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8414 - accuracy: 0.6867 - val_loss: 0.8591 - val_accuracy: 0.6820\n",
      "Epoch 74/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8395 - accuracy: 0.6908 - val_loss: 0.8575 - val_accuracy: 0.6790\n",
      "Epoch 75/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8362 - accuracy: 0.6905 - val_loss: 0.8583 - val_accuracy: 0.6800\n",
      "Epoch 76/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8338 - accuracy: 0.6915 - val_loss: 0.8543 - val_accuracy: 0.6810\n",
      "Epoch 77/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8313 - accuracy: 0.6938 - val_loss: 0.8608 - val_accuracy: 0.6720\n",
      "Epoch 78/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8294 - accuracy: 0.6915 - val_loss: 0.8506 - val_accuracy: 0.6870\n",
      "Epoch 79/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8271 - accuracy: 0.6982 - val_loss: 0.8493 - val_accuracy: 0.6860\n",
      "Epoch 80/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8248 - accuracy: 0.6940 - val_loss: 0.8488 - val_accuracy: 0.6780\n",
      "Epoch 81/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8229 - accuracy: 0.6975 - val_loss: 0.8441 - val_accuracy: 0.6820\n",
      "Epoch 82/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8204 - accuracy: 0.6975 - val_loss: 0.8446 - val_accuracy: 0.6790\n",
      "Epoch 83/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8172 - accuracy: 0.6965 - val_loss: 0.8404 - val_accuracy: 0.6840\n",
      "Epoch 84/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8140 - accuracy: 0.7023 - val_loss: 0.8462 - val_accuracy: 0.6790\n",
      "Epoch 85/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8135 - accuracy: 0.7017 - val_loss: 0.8366 - val_accuracy: 0.6940\n",
      "Epoch 86/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8107 - accuracy: 0.6980 - val_loss: 0.8366 - val_accuracy: 0.6810\n",
      "Epoch 87/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8094 - accuracy: 0.7007 - val_loss: 0.8362 - val_accuracy: 0.6820\n",
      "Epoch 88/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8061 - accuracy: 0.6990 - val_loss: 0.8340 - val_accuracy: 0.6830\n",
      "Epoch 89/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8046 - accuracy: 0.7045 - val_loss: 0.8301 - val_accuracy: 0.6870\n",
      "Epoch 90/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8015 - accuracy: 0.7042 - val_loss: 0.8363 - val_accuracy: 0.6750\n",
      "Epoch 91/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.8001 - accuracy: 0.7042 - val_loss: 0.8253 - val_accuracy: 0.6980\n",
      "Epoch 92/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7970 - accuracy: 0.7050 - val_loss: 0.8250 - val_accuracy: 0.6980\n",
      "Epoch 93/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7948 - accuracy: 0.7055 - val_loss: 0.8227 - val_accuracy: 0.6880\n",
      "Epoch 94/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7921 - accuracy: 0.7078 - val_loss: 0.8202 - val_accuracy: 0.7000\n",
      "Epoch 95/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7893 - accuracy: 0.7105 - val_loss: 0.8190 - val_accuracy: 0.6950\n",
      "Epoch 96/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7869 - accuracy: 0.7080 - val_loss: 0.8233 - val_accuracy: 0.6810\n",
      "Epoch 97/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7871 - accuracy: 0.7115 - val_loss: 0.8190 - val_accuracy: 0.6850\n",
      "Epoch 98/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7820 - accuracy: 0.7097 - val_loss: 0.8119 - val_accuracy: 0.6990\n",
      "Epoch 99/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7805 - accuracy: 0.7115 - val_loss: 0.8110 - val_accuracy: 0.6970\n",
      "Epoch 100/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7781 - accuracy: 0.7117 - val_loss: 0.8134 - val_accuracy: 0.6900\n",
      "Epoch 101/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7773 - accuracy: 0.7132 - val_loss: 0.8098 - val_accuracy: 0.6880\n",
      "Epoch 102/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7743 - accuracy: 0.7115 - val_loss: 0.8078 - val_accuracy: 0.6960\n",
      "Epoch 103/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7708 - accuracy: 0.7153 - val_loss: 0.8044 - val_accuracy: 0.6940\n",
      "Epoch 104/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7689 - accuracy: 0.7163 - val_loss: 0.8048 - val_accuracy: 0.6930\n",
      "Epoch 105/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7661 - accuracy: 0.7165 - val_loss: 0.8050 - val_accuracy: 0.6910\n",
      "Epoch 106/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7652 - accuracy: 0.7178 - val_loss: 0.7991 - val_accuracy: 0.6970\n",
      "Epoch 107/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7626 - accuracy: 0.7193 - val_loss: 0.7953 - val_accuracy: 0.7030\n",
      "Epoch 108/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7596 - accuracy: 0.7188 - val_loss: 0.7959 - val_accuracy: 0.6960\n",
      "Epoch 109/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7575 - accuracy: 0.7210 - val_loss: 0.7937 - val_accuracy: 0.7110\n",
      "Epoch 110/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7557 - accuracy: 0.7207 - val_loss: 0.7910 - val_accuracy: 0.7030\n",
      "Epoch 111/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7534 - accuracy: 0.7255 - val_loss: 0.7890 - val_accuracy: 0.7000\n",
      "Epoch 112/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7502 - accuracy: 0.7225 - val_loss: 0.7883 - val_accuracy: 0.6970\n",
      "Epoch 113/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7483 - accuracy: 0.7247 - val_loss: 0.7911 - val_accuracy: 0.6950\n",
      "Epoch 114/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7472 - accuracy: 0.7240 - val_loss: 0.7857 - val_accuracy: 0.6950\n",
      "Epoch 115/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7445 - accuracy: 0.7275 - val_loss: 0.7821 - val_accuracy: 0.7030\n",
      "Epoch 116/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7419 - accuracy: 0.7297 - val_loss: 0.7867 - val_accuracy: 0.6960\n",
      "Epoch 117/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7398 - accuracy: 0.7290 - val_loss: 0.7845 - val_accuracy: 0.6980\n",
      "Epoch 118/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7378 - accuracy: 0.7290 - val_loss: 0.7775 - val_accuracy: 0.7060\n",
      "Epoch 119/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7351 - accuracy: 0.7315 - val_loss: 0.7752 - val_accuracy: 0.7050\n",
      "Epoch 120/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7325 - accuracy: 0.7315 - val_loss: 0.7742 - val_accuracy: 0.7060\n",
      "Epoch 121/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7295 - accuracy: 0.7330 - val_loss: 0.7694 - val_accuracy: 0.7110\n",
      "Epoch 122/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7278 - accuracy: 0.7315 - val_loss: 0.7683 - val_accuracy: 0.7150\n",
      "Epoch 123/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7266 - accuracy: 0.7347 - val_loss: 0.7668 - val_accuracy: 0.7070\n",
      "Epoch 124/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7239 - accuracy: 0.7337 - val_loss: 0.7642 - val_accuracy: 0.7190\n",
      "Epoch 125/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7227 - accuracy: 0.7350 - val_loss: 0.7646 - val_accuracy: 0.7200\n",
      "Epoch 126/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7199 - accuracy: 0.7372 - val_loss: 0.7742 - val_accuracy: 0.6980\n",
      "Epoch 127/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7175 - accuracy: 0.7365 - val_loss: 0.7596 - val_accuracy: 0.7220\n",
      "Epoch 128/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7149 - accuracy: 0.7400 - val_loss: 0.7575 - val_accuracy: 0.7130\n",
      "Epoch 129/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7132 - accuracy: 0.7352 - val_loss: 0.7547 - val_accuracy: 0.7240\n",
      "Epoch 130/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7096 - accuracy: 0.7423 - val_loss: 0.7541 - val_accuracy: 0.7230\n",
      "Epoch 131/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 0.7408 - val_loss: 0.7526 - val_accuracy: 0.7160\n",
      "Epoch 132/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7055 - accuracy: 0.7390 - val_loss: 0.7488 - val_accuracy: 0.7230\n",
      "Epoch 133/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7037 - accuracy: 0.7435 - val_loss: 0.7466 - val_accuracy: 0.7310\n",
      "Epoch 134/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7025 - accuracy: 0.7448 - val_loss: 0.7459 - val_accuracy: 0.7210\n",
      "Epoch 135/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.7013 - accuracy: 0.7448 - val_loss: 0.7462 - val_accuracy: 0.7160\n",
      "Epoch 136/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.6978 - accuracy: 0.7418 - val_loss: 0.7436 - val_accuracy: 0.7240\n",
      "Epoch 137/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.6959 - accuracy: 0.7467 - val_loss: 0.7436 - val_accuracy: 0.7230\n",
      "Epoch 138/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.7442 - val_loss: 0.7393 - val_accuracy: 0.7240\n",
      "Epoch 139/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.6917 - accuracy: 0.7450 - val_loss: 0.7374 - val_accuracy: 0.7280\n",
      "Epoch 140/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.6897 - accuracy: 0.7483 - val_loss: 0.7390 - val_accuracy: 0.7230\n",
      "Epoch 141/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.7492 - val_loss: 0.7339 - val_accuracy: 0.7250\n",
      "Epoch 142/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.6853 - accuracy: 0.7483 - val_loss: 0.7393 - val_accuracy: 0.7150\n",
      "Epoch 143/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.7502 - val_loss: 0.7314 - val_accuracy: 0.7240\n",
      "Epoch 144/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.7500 - val_loss: 0.7293 - val_accuracy: 0.7260\n",
      "Epoch 145/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.7513 - val_loss: 0.7281 - val_accuracy: 0.7280\n",
      "Epoch 146/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.6780 - accuracy: 0.7525 - val_loss: 0.7272 - val_accuracy: 0.7240\n",
      "Epoch 147/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.7513 - val_loss: 0.7232 - val_accuracy: 0.7360\n",
      "Epoch 148/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.6747 - accuracy: 0.7513 - val_loss: 0.7222 - val_accuracy: 0.7310\n",
      "Epoch 149/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.6711 - accuracy: 0.7565 - val_loss: 0.7201 - val_accuracy: 0.7260\n",
      "Epoch 150/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.7542 - val_loss: 0.7200 - val_accuracy: 0.7350\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=150, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "loss = history_dict['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, acc, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 501us/step - loss: 0.7200 - accuracy: 0.7350\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 630us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0,\n 3,\n 3,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 3,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 3,\n 0,\n 4,\n 0,\n 3,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 4,\n 3,\n 0,\n 1,\n 0,\n 0,\n 0,\n 3,\n 3,\n 2,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 3,\n 2,\n 2,\n 0,\n 3,\n 3,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 3,\n 0,\n 4,\n 0,\n 0,\n 0,\n 2,\n 0,\n 4,\n 0,\n 0,\n 2,\n 4,\n 4,\n 0,\n 3,\n 4,\n 4,\n 4,\n 0,\n 3,\n 3,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 2,\n 0,\n 0,\n 2,\n 0,\n 3,\n 3,\n 4,\n 0,\n 4,\n 0,\n 3,\n 0,\n 4,\n 1,\n 3,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 4,\n 0,\n 0,\n 0,\n 3,\n 0,\n 0,\n 0,\n 3,\n 3,\n 0,\n 3,\n 0,\n 4,\n 1,\n 0,\n 3,\n 0,\n 4,\n 0,\n 2,\n 3,\n 4,\n 0,\n 0,\n 0,\n 3,\n 0,\n 2,\n 1,\n 0,\n 0,\n 1,\n 0,\n 4,\n 2,\n 0,\n 3,\n 0,\n 1,\n 0,\n 2,\n 0,\n 1,\n 2,\n 3,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 3,\n 1,\n 2,\n 4,\n 0,\n 0,\n 1,\n 3,\n 0,\n 3,\n 0,\n 1,\n 0,\n 1,\n 0,\n 4,\n 0,\n 4,\n 0,\n 3,\n 1,\n 3,\n 4,\n 0,\n 2,\n 0,\n 3,\n 0,\n 0,\n 0,\n 2,\n 4,\n 4,\n 0,\n 0,\n 3,\n 0,\n 0,\n 4,\n 3,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 3,\n 3,\n 0,\n 3,\n 0,\n 2,\n 0,\n 4,\n 0,\n 0,\n 0,\n 4,\n 4,\n 0,\n 3,\n 1,\n 0,\n 4,\n 3,\n 0,\n 0,\n 3,\n 3,\n 4,\n 0,\n 3,\n 4,\n 2,\n 3,\n 3,\n 0,\n 0,\n 3,\n 0,\n 1,\n 1,\n 0,\n 0,\n 3,\n 0,\n 0,\n 3,\n 3,\n 0,\n 1,\n 0,\n 0,\n 4,\n 3,\n 0,\n 3,\n 4,\n 0,\n 0,\n 0,\n 1,\n 0,\n 3,\n 2,\n 0,\n 2,\n 0,\n 4,\n 0,\n 3,\n 3,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 4,\n 2,\n 2,\n 0,\n 0,\n 3,\n 1,\n 4,\n 1,\n 3,\n 3,\n 4,\n 3,\n 3,\n 3,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 3,\n 2,\n 3,\n 1,\n 3,\n 0,\n 1,\n 4,\n 3,\n 0,\n 4,\n 4,\n 1,\n 0,\n 4,\n 3,\n 4,\n 0,\n 1,\n 2,\n 0,\n 1,\n 0,\n 0,\n 4,\n 0,\n 0,\n 1,\n 0,\n 0,\n 3,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 3,\n 0,\n 3,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 3,\n 0,\n 3,\n 0,\n 3,\n 3,\n 2,\n 3,\n 0,\n 0,\n 0,\n 0,\n 0,\n 3,\n 0,\n 4,\n 3,\n 3,\n 0,\n 4,\n 3,\n 3,\n 0,\n 3,\n 0,\n 4,\n 0,\n 4,\n 0,\n 2,\n 3,\n 0,\n 1,\n 0,\n 0,\n 1,\n 3,\n 3,\n 0,\n 0,\n 0,\n 0,\n 0,\n 4,\n 0,\n 3,\n 0,\n 1,\n 0,\n 0,\n 4,\n 3,\n 0,\n 3,\n 0,\n 2,\n 0,\n 3,\n 0,\n 0,\n 4,\n 4,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 3,\n 0,\n 3,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 4,\n 4,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 2,\n 0,\n 0,\n 0,\n 0,\n 0,\n 3,\n 0,\n 3,\n 0,\n 4,\n 3,\n 0,\n 0,\n 0,\n 0,\n 0,\n 2,\n 0,\n 1,\n 2,\n 4,\n 0,\n 3,\n 3,\n 1,\n 3,\n 0,\n 3,\n 0,\n 0,\n 3,\n 0,\n 0,\n 3,\n 3,\n 0,\n 3,\n 0,\n 0,\n 0,\n 3,\n 1,\n 0,\n 3,\n 0,\n 3,\n 3,\n 4,\n 3,\n 3,\n 0,\n 0,\n 3,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 3,\n 3,\n 0,\n 3,\n 0,\n 0,\n 3,\n 0,\n 0,\n 3,\n 4,\n 0,\n 1,\n 0,\n 4,\n 0,\n 3,\n 0,\n 0,\n 4,\n 0,\n 3,\n 0,\n 4,\n 2,\n 4,\n 3,\n 0,\n 3,\n 0,\n 3,\n 1,\n 3,\n 0,\n 0,\n 0,\n 3,\n 3,\n 3,\n 3,\n 0,\n 0,\n 0,\n 4,\n 3,\n 0,\n 0,\n 3,\n 3,\n 0,\n 3,\n 3,\n 4,\n 3,\n 0,\n 3,\n 0,\n 3,\n 0,\n 3,\n 0,\n 4,\n 1,\n 3,\n 0,\n 3,\n 0,\n 3,\n 0,\n 0,\n 4,\n 0,\n 3,\n 4,\n 3,\n 3,\n 3,\n 2,\n 0,\n 0,\n 0,\n 2,\n 0,\n 0,\n 3,\n 3,\n 0,\n 3,\n 4,\n 3,\n 3,\n 3,\n 0,\n 3,\n 0,\n 1,\n 0,\n 3,\n 0,\n 1,\n 3,\n 3,\n 1,\n 3,\n 1,\n 0,\n 3,\n 0,\n 4,\n 4,\n 4,\n 3,\n 0,\n 0,\n 3,\n 0,\n 3,\n 4,\n 0,\n 0,\n 0,\n 0,\n 4,\n 1,\n 0,\n 2,\n 3,\n 4,\n 0,\n 3,\n 0,\n 2,\n 0,\n 0,\n 0,\n 0,\n 0,\n 4,\n 0,\n 3,\n 0,\n 0,\n 0,\n 1,\n 3,\n 0,\n 0,\n 1,\n 3,\n 0,\n 4,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 3,\n 4,\n 3,\n 0,\n 3,\n 0,\n 3,\n 3,\n 0,\n 0,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 4,\n 0,\n 0,\n 3,\n 0,\n 1,\n 2,\n 3,\n 0,\n 0,\n 3,\n 0,\n 3,\n 3,\n 0,\n 3,\n 0,\n 0,\n 0,\n 0,\n 3,\n 0,\n 0,\n 0,\n 2,\n 1,\n 0,\n 3,\n 3,\n 4,\n 0,\n 3,\n 0,\n 3,\n 0,\n 0,\n 1,\n 4,\n 0,\n 3,\n 4,\n 0,\n 0,\n 3,\n 2,\n 0,\n 1,\n 0,\n 3,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 3,\n 0,\n 3,\n 4,\n 4,\n 0,\n 3,\n 3,\n 3,\n 2,\n 4,\n 3,\n 1,\n 2,\n 1,\n 0,\n 3,\n 4,\n 0,\n 0,\n 0,\n 1,\n 0,\n 3,\n 0,\n 0,\n 3,\n 0,\n 3,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 2,\n 0,\n 2,\n 3,\n 0,\n 0,\n 2,\n 4,\n 4,\n 0,\n 0,\n 0,\n 0,\n 0,\n 3,\n 0,\n 4,\n 3,\n 3,\n 3,\n 0,\n 0,\n 0,\n 3,\n 0,\n 3,\n 3,\n 0,\n 0,\n 3,\n 1,\n 4,\n 0,\n 3,\n 0,\n 0,\n 3,\n 4,\n 0,\n 0,\n 3,\n 3,\n 1,\n 0,\n 0,\n 3,\n 3,\n 0,\n 0,\n 3,\n 3,\n 0,\n 0,\n 0,\n 2,\n 0,\n 0,\n 0,\n 0,\n 2,\n 0,\n 0,\n 3,\n 3,\n 0,\n 0,\n 0,\n 3,\n 3,\n 3,\n 0,\n 0,\n 4,\n 0,\n 3,\n 4,\n 0,\n 0,\n 2,\n 3,\n 1,\n 2,\n 0,\n 3,\n 0,\n 4,\n 0,\n 0,\n 0,\n 4,\n 0,\n 0,\n 3,\n 0,\n 4,\n 0,\n 3,\n 0,\n 0,\n 0,\n 0,\n 3,\n 0,\n 4,\n 0,\n 3,\n 3,\n 4,\n 3,\n 0,\n 0,\n 0,\n 2,\n 0,\n 0,\n 3,\n 0,\n 3,\n 0,\n 0,\n 0,\n 0,\n 3,\n 4,\n 0,\n 3,\n 3,\n 0,\n 2,\n 0,\n 2,\n 3,\n 0,\n 4,\n 4,\n 0,\n 0,\n 0,\n 0,\n 0,\n 3,\n 0,\n 0,\n 1,\n 0,\n 1,\n 1,\n 3,\n 0,\n 0,\n 0,\n 4,\n 0,\n 4,\n 0,\n 3,\n 4,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 3,\n 0,\n 3,\n 4,\n 2,\n 0,\n 1,\n 3,\n 0,\n 4,\n 0,\n 3,\n 0,\n 3,\n 0,\n 3,\n 0,\n 2,\n 1,\n 3,\n 3,\n 1,\n 0,\n 1,\n 3,\n 4,\n 1,\n 4,\n 3,\n 3,\n 0,\n 3,\n 0,\n 3,\n 1,\n 0,\n 3,\n 1,\n 1,\n 2,\n 0,\n 2,\n 3,\n 3,\n 0,\n 3,\n 0,\n 0,\n 0,\n 0,\n 4,\n 1,\n 0,\n 3,\n 4,\n 0,\n 3,\n 0,\n 4]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = model.predict(X_test)\n",
    "\n",
    "categories_predicted = [np.argmax(pred) for pred in predicts]\n",
    "\n",
    "categories_predicted"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "1718    0\n2511    1\n345     1\n2521    0\n54      0\n       ..\n3900    4\n3753    0\n3582    3\n2392    0\n3343    4\nName: incidents, Length: 1000, dtype: int64"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Obter as previsões no dataset de submissão"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "      delay_in_seconds  affected_roads  luminosity  avg_temperature  \\\n0             0.081461        0.142857         0.5         0.464286   \n1             0.000000        0.142857         1.0         0.500000   \n2             0.000000        0.142857         0.5         0.714286   \n3             0.009417        0.285714         0.5         0.571429   \n4             0.000000        0.142857         0.5         0.642857   \n...                ...             ...         ...              ...   \n1201          0.000000        0.142857         0.5         0.357143   \n1202          0.002960        0.142857         1.0         0.785714   \n1203          0.084824        0.142857         0.5         0.392857   \n1204          0.016548        0.142857         0.5         0.464286   \n1205          0.000000        0.142857         0.5         0.607143   \n\n      avg_atm_pressure  avg_humidity  avg_wind_speed  avg_rain  \\\n0              0.59375      0.784946        0.000000       0.0   \n1              0.59375      0.365591        0.222222       0.0   \n2              0.56250      0.688172        0.000000       0.0   \n3              0.28125      0.795699        0.333333       0.0   \n4              0.71875      0.849462        0.000000       0.0   \n...                ...           ...             ...       ...   \n1201           0.81250      0.677419        0.222222       0.0   \n1202           0.53125      0.344086        0.222222       0.0   \n1203           0.59375      0.569892        0.000000       0.0   \n1204           0.50000      0.462366        0.111111       0.0   \n1205           0.71875      0.408602        0.111111       0.0   \n\n      record_date_hour  record_date_day  record_date_month  \\\n0             0.826087         0.400000           0.272727   \n1             0.173913         0.400000           0.818182   \n2             0.826087         0.566667           0.545455   \n3             0.652174         0.966667           0.818182   \n4             0.434783         0.566667           0.818182   \n...                ...              ...                ...   \n1201          0.434783         1.000000           1.000000   \n1202          0.000000         0.500000           0.545455   \n1203          0.652174         0.600000           1.000000   \n1204          0.739130         0.233333           0.181818   \n1205          0.434783         0.166667           0.454545   \n\n      record_date_weekday  \n0                0.166667  \n1                0.333333  \n2                1.000000  \n3                0.833333  \n4                0.000000  \n...                   ...  \n1201             0.666667  \n1202             0.666667  \n1203             1.000000  \n1204             0.000000  \n1205             1.000000  \n\n[1206 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>delay_in_seconds</th>\n      <th>affected_roads</th>\n      <th>luminosity</th>\n      <th>avg_temperature</th>\n      <th>avg_atm_pressure</th>\n      <th>avg_humidity</th>\n      <th>avg_wind_speed</th>\n      <th>avg_rain</th>\n      <th>record_date_hour</th>\n      <th>record_date_day</th>\n      <th>record_date_month</th>\n      <th>record_date_weekday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.081461</td>\n      <td>0.142857</td>\n      <td>0.5</td>\n      <td>0.464286</td>\n      <td>0.59375</td>\n      <td>0.784946</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.826087</td>\n      <td>0.400000</td>\n      <td>0.272727</td>\n      <td>0.166667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.142857</td>\n      <td>1.0</td>\n      <td>0.500000</td>\n      <td>0.59375</td>\n      <td>0.365591</td>\n      <td>0.222222</td>\n      <td>0.0</td>\n      <td>0.173913</td>\n      <td>0.400000</td>\n      <td>0.818182</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.142857</td>\n      <td>0.5</td>\n      <td>0.714286</td>\n      <td>0.56250</td>\n      <td>0.688172</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.826087</td>\n      <td>0.566667</td>\n      <td>0.545455</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.009417</td>\n      <td>0.285714</td>\n      <td>0.5</td>\n      <td>0.571429</td>\n      <td>0.28125</td>\n      <td>0.795699</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.652174</td>\n      <td>0.966667</td>\n      <td>0.818182</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.142857</td>\n      <td>0.5</td>\n      <td>0.642857</td>\n      <td>0.71875</td>\n      <td>0.849462</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.434783</td>\n      <td>0.566667</td>\n      <td>0.818182</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1201</th>\n      <td>0.000000</td>\n      <td>0.142857</td>\n      <td>0.5</td>\n      <td>0.357143</td>\n      <td>0.81250</td>\n      <td>0.677419</td>\n      <td>0.222222</td>\n      <td>0.0</td>\n      <td>0.434783</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>1202</th>\n      <td>0.002960</td>\n      <td>0.142857</td>\n      <td>1.0</td>\n      <td>0.785714</td>\n      <td>0.53125</td>\n      <td>0.344086</td>\n      <td>0.222222</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.545455</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>1203</th>\n      <td>0.084824</td>\n      <td>0.142857</td>\n      <td>0.5</td>\n      <td>0.392857</td>\n      <td>0.59375</td>\n      <td>0.569892</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.652174</td>\n      <td>0.600000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1204</th>\n      <td>0.016548</td>\n      <td>0.142857</td>\n      <td>0.5</td>\n      <td>0.464286</td>\n      <td>0.50000</td>\n      <td>0.462366</td>\n      <td>0.111111</td>\n      <td>0.0</td>\n      <td>0.739130</td>\n      <td>0.233333</td>\n      <td>0.181818</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1205</th>\n      <td>0.000000</td>\n      <td>0.142857</td>\n      <td>0.5</td>\n      <td>0.607143</td>\n      <td>0.71875</td>\n      <td>0.408602</td>\n      <td>0.111111</td>\n      <td>0.0</td>\n      <td>0.434783</td>\n      <td>0.166667</td>\n      <td>0.454545</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1206 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = neural_network_data_preparation(test_df)\n",
    "\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "X_scaled = pd.DataFrame(scaler_X.transform(X[X.columns]), columns=X.columns)\n",
    "\n",
    "X_scaled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 686us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[1.52413477e-08, 4.09123197e-04, 2.37359107e-03, 7.54288286e-02,\n        9.21788394e-01],\n       [8.18769336e-01, 1.69369355e-01, 9.92000010e-03, 1.92007620e-03,\n        2.12839241e-05],\n       [6.13695025e-01, 1.74736843e-01, 9.03705433e-02, 1.16669051e-01,\n        4.52848338e-03],\n       ...,\n       [1.62932804e-04, 3.32928419e-01, 1.64157778e-01, 3.90572309e-01,\n        1.12178609e-01],\n       [1.24576123e-04, 4.45571542e-02, 4.18528020e-02, 2.98368812e-01,\n        6.15096629e-01],\n       [1.15508154e-01, 7.92004913e-02, 9.86063331e-02, 6.47278309e-01,\n        5.94067462e-02]], dtype=float32)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_prob_predictions = model.predict(X_scaled)\n",
    "\n",
    "categories_prob_predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "[4, 0, 0, 1, 0, 4, 4, 0, 3, 0]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_predictions = [np.argmax(pred) for pred in categories_prob_predictions]\n",
    "\n",
    "numerical_predictions[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "numerical_predictions_df = pd.DataFrame(numerical_predictions)\n",
    "\n",
    "incidents_categories = {\n",
    "    0: 'None',\n",
    "    1: 'Low',\n",
    "    2: 'Medium',\n",
    "    3: 'High',\n",
    "    4: 'Very_High',\n",
    "}\n",
    "\n",
    "predictions_df = numerical_predictions_df.replace(incidents_categories)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "predictions_df.index += 1\n",
    "\n",
    "predictions_df.to_csv(\"submission.csv\", header=['Incidents'], index_label='RowId')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
