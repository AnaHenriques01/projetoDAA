{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "from tensorflow.python.keras.losses import SparseCategoricalCrossentropy\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "print(tf.__version__)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Carregamento de dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TRAINING_DATASET_SOURCE = 'training_data.csv'\n",
    "TEST_DATASET_SOURCE = 'test_data.csv'\n",
    "\n",
    "train_df = pd.read_csv(TRAINING_DATASET_SOURCE)\n",
    "test_df = pd.read_csv(TEST_DATASET_SOURCE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SEED utilizada"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SEED = 101"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparação dos dados"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "categorical_to_numerical = {\n",
    "    'avg_rain': {\n",
    "        'Sem Chuva': 0,\n",
    "        'chuva fraca': 1,\n",
    "        'chuva moderada': 2,\n",
    "        'chuva forte': 3\n",
    "    },\n",
    "    'luminosity': {\n",
    "        'LOW_LIGHT': 0,\n",
    "        'LIGHT': 1,\n",
    "        'DARK': 2,\n",
    "    }\n",
    "}\n",
    "\n",
    "incidents_to_numerical = {\n",
    "    'incidents': {\n",
    "        'None': 0,\n",
    "        'Low': 1,\n",
    "        'Medium': 2,\n",
    "        'High': 3,\n",
    "        'Very_High': 4,\n",
    "    }\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def neural_network_data_preparation(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    dropped_columns = ['city_name', 'magnitude_of_delay', 'avg_precipitation']\n",
    "\n",
    "    prep_df = df.drop(dropped_columns, axis=1)\n",
    "\n",
    "    ### Extrair a hora e dia da semana da feature 'record_date'\n",
    "    record_date = pd.DatetimeIndex(prep_df['record_date'])\n",
    "\n",
    "    prep_df['record_date_hour'] = record_date.hour\n",
    "    prep_df['record_date_day'] = record_date.day\n",
    "    prep_df['record_date_month'] = record_date.month\n",
    "    prep_df['record_date_weekday'] = record_date.weekday\n",
    "\n",
    "    prep_df.drop(columns=['record_date'], inplace=True)\n",
    "\n",
    "    ### Quantificar a feature 'affected_roads' para o número único de estradas afetadas\n",
    "    road_quantity = []\n",
    "    for line in prep_df['affected_roads']:\n",
    "        res = set(str(line).split(','))\n",
    "        res2 = [elem for elem in res if elem != '']\n",
    "        count = len(res2)\n",
    "        road_quantity.append(count)\n",
    "\n",
    "    prep_df['affected_roads'] = road_quantity\n",
    "\n",
    "    prep_df.replace(categorical_to_numerical, inplace=True)\n",
    "\n",
    "    ### Target\n",
    "    if 'incidents' in prep_df.columns:\n",
    "        prep_df.replace(incidents_to_numerical, inplace=True)\n",
    "\n",
    "    return prep_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = neural_network_data_preparation(train_df)\n",
    "y = X['incidents']\n",
    "\n",
    "X.drop(columns=['incidents'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler_X = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "X_scaled = pd.DataFrame(scaler_X.transform(X[X.columns]), columns=X.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Construção da estrutura da rede neuronal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install -q -U keras-tuner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    # Create a sequential model (with three layers - last one is the output)\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    input_hp_units = hp.Int('units', min_value=5, max_value=200, step=5)\n",
    "\n",
    "    model.add(Dense(input_hp_units, input_dim=12, activation='relu'))\n",
    "\n",
    "    hp_units = hp.Int('units', min_value=5, max_value=200, step=5)\n",
    "\n",
    "    hp_activation = hp.Choice(\"activation\", [\"relu\", \"tanh\", 'sigmoid'])\n",
    "\n",
    "    model.add(Dense(hp_units, activation=hp_activation))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5])\n",
    "\n",
    "    # Model compilation\n",
    "    model.compile(loss=SparseCategoricalCrossentropy(), optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"accuracy\",\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    overwrite=True,\n",
    "    directory=\"trials\",\n",
    "    project_name=\"competition\",\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "tuner.search(X, y, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X, y, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(X, y, epochs=best_epoch, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eval_result = hypermodel.evaluate(X, y)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-------\n",
    "-------\n",
    "-------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1683 - accuracy: 0.9390 - val_loss: 0.4177 - val_accuracy: 0.8730\n",
      "Epoch 2/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1661 - accuracy: 0.9383 - val_loss: 0.4167 - val_accuracy: 0.8760\n",
      "Epoch 3/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1684 - accuracy: 0.9405 - val_loss: 0.4064 - val_accuracy: 0.8780\n",
      "Epoch 4/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.9373 - val_loss: 0.4051 - val_accuracy: 0.8730\n",
      "Epoch 5/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1634 - accuracy: 0.9442 - val_loss: 0.4072 - val_accuracy: 0.8750\n",
      "Epoch 6/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1640 - accuracy: 0.9440 - val_loss: 0.4284 - val_accuracy: 0.8700\n",
      "Epoch 7/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1679 - accuracy: 0.9420 - val_loss: 0.4509 - val_accuracy: 0.8730\n",
      "Epoch 8/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1676 - accuracy: 0.9410 - val_loss: 0.4303 - val_accuracy: 0.8760\n",
      "Epoch 9/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1612 - accuracy: 0.9383 - val_loss: 0.4184 - val_accuracy: 0.8710\n",
      "Epoch 10/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1647 - accuracy: 0.9420 - val_loss: 0.4010 - val_accuracy: 0.8820\n",
      "Epoch 11/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1584 - accuracy: 0.9455 - val_loss: 0.3989 - val_accuracy: 0.8820\n",
      "Epoch 12/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1610 - accuracy: 0.9417 - val_loss: 0.3959 - val_accuracy: 0.8860\n",
      "Epoch 13/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.9345 - val_loss: 0.4213 - val_accuracy: 0.8740\n",
      "Epoch 14/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1594 - accuracy: 0.9460 - val_loss: 0.4064 - val_accuracy: 0.8820\n",
      "Epoch 15/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1626 - accuracy: 0.9425 - val_loss: 0.4066 - val_accuracy: 0.8760\n",
      "Epoch 16/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1589 - accuracy: 0.9438 - val_loss: 0.4022 - val_accuracy: 0.8750\n",
      "Epoch 17/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1641 - accuracy: 0.9405 - val_loss: 0.4048 - val_accuracy: 0.8790\n",
      "Epoch 18/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1564 - accuracy: 0.9435 - val_loss: 0.4188 - val_accuracy: 0.8810\n",
      "Epoch 19/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1600 - accuracy: 0.9420 - val_loss: 0.4068 - val_accuracy: 0.8810\n",
      "Epoch 20/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1633 - accuracy: 0.9420 - val_loss: 0.4518 - val_accuracy: 0.8550\n",
      "Epoch 21/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.9365 - val_loss: 0.4590 - val_accuracy: 0.8630\n",
      "Epoch 22/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1652 - accuracy: 0.9390 - val_loss: 0.4713 - val_accuracy: 0.8580\n",
      "Epoch 23/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9450 - val_loss: 0.3969 - val_accuracy: 0.8810\n",
      "Epoch 24/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9492 - val_loss: 0.4158 - val_accuracy: 0.8810\n",
      "Epoch 25/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9442 - val_loss: 0.4421 - val_accuracy: 0.8720\n",
      "Epoch 26/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1525 - accuracy: 0.9460 - val_loss: 0.4273 - val_accuracy: 0.8730\n",
      "Epoch 27/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1510 - accuracy: 0.9480 - val_loss: 0.4017 - val_accuracy: 0.8790\n",
      "Epoch 28/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1491 - accuracy: 0.9492 - val_loss: 0.3976 - val_accuracy: 0.8830\n",
      "Epoch 29/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1551 - accuracy: 0.9452 - val_loss: 0.4093 - val_accuracy: 0.8790\n",
      "Epoch 30/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1498 - accuracy: 0.9485 - val_loss: 0.4166 - val_accuracy: 0.8760\n",
      "Epoch 31/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1596 - accuracy: 0.9445 - val_loss: 0.3973 - val_accuracy: 0.8820\n",
      "Epoch 32/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1500 - accuracy: 0.9495 - val_loss: 0.4368 - val_accuracy: 0.8650\n",
      "Epoch 33/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1473 - accuracy: 0.9507 - val_loss: 0.4076 - val_accuracy: 0.8810\n",
      "Epoch 34/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9473 - val_loss: 0.4123 - val_accuracy: 0.8770\n",
      "Epoch 35/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1509 - accuracy: 0.9473 - val_loss: 0.4178 - val_accuracy: 0.8810\n",
      "Epoch 36/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1460 - accuracy: 0.9500 - val_loss: 0.4049 - val_accuracy: 0.8850\n",
      "Epoch 37/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1540 - accuracy: 0.9465 - val_loss: 0.3996 - val_accuracy: 0.8770\n",
      "Epoch 38/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.9495 - val_loss: 0.4612 - val_accuracy: 0.8630\n",
      "Epoch 39/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1507 - accuracy: 0.9467 - val_loss: 0.4178 - val_accuracy: 0.8840\n",
      "Epoch 40/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9482 - val_loss: 0.4116 - val_accuracy: 0.8860\n",
      "Epoch 41/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1507 - accuracy: 0.9470 - val_loss: 0.4350 - val_accuracy: 0.8760\n",
      "Epoch 42/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1490 - accuracy: 0.9507 - val_loss: 0.4062 - val_accuracy: 0.8800\n",
      "Epoch 43/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9492 - val_loss: 0.4244 - val_accuracy: 0.8760\n",
      "Epoch 44/150\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1617 - accuracy: 0.9442 - val_loss: 0.4395 - val_accuracy: 0.8760\n",
      "Epoch 45/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1468 - accuracy: 0.9490 - val_loss: 0.4064 - val_accuracy: 0.8870\n",
      "Epoch 46/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9507 - val_loss: 0.4261 - val_accuracy: 0.8760\n",
      "Epoch 47/150\n",
      "125/125 [==============================] - 0s 4ms/step - loss: 0.1465 - accuracy: 0.9498 - val_loss: 0.4291 - val_accuracy: 0.8750\n",
      "Epoch 48/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9482 - val_loss: 0.4355 - val_accuracy: 0.8800\n",
      "Epoch 49/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9503 - val_loss: 0.4315 - val_accuracy: 0.8780\n",
      "Epoch 50/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9498 - val_loss: 0.4025 - val_accuracy: 0.8780\n",
      "Epoch 51/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9523 - val_loss: 0.4092 - val_accuracy: 0.8830\n",
      "Epoch 52/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1424 - accuracy: 0.9507 - val_loss: 0.4294 - val_accuracy: 0.8700\n",
      "Epoch 53/150\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.9492 - val_loss: 0.4208 - val_accuracy: 0.8720\n",
      "Epoch 54/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1386 - accuracy: 0.9538 - val_loss: 0.4110 - val_accuracy: 0.8790\n",
      "Epoch 55/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1370 - accuracy: 0.9515 - val_loss: 0.4365 - val_accuracy: 0.8770\n",
      "Epoch 56/150\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9532 - val_loss: 0.4459 - val_accuracy: 0.8730\n",
      "Epoch 57/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9525 - val_loss: 0.4821 - val_accuracy: 0.8600\n",
      "Epoch 58/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1426 - accuracy: 0.9530 - val_loss: 0.4190 - val_accuracy: 0.8780\n",
      "Epoch 59/150\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9477 - val_loss: 0.4481 - val_accuracy: 0.8740\n",
      "Epoch 60/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9488 - val_loss: 0.4150 - val_accuracy: 0.8840\n",
      "Epoch 61/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1381 - accuracy: 0.9525 - val_loss: 0.4196 - val_accuracy: 0.8840\n",
      "Epoch 62/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1329 - accuracy: 0.9563 - val_loss: 0.4183 - val_accuracy: 0.8860\n",
      "Epoch 63/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1431 - accuracy: 0.9515 - val_loss: 0.4273 - val_accuracy: 0.8840\n",
      "Epoch 64/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1391 - accuracy: 0.9525 - val_loss: 0.4050 - val_accuracy: 0.8790\n",
      "Epoch 65/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9555 - val_loss: 0.4192 - val_accuracy: 0.8890\n",
      "Epoch 66/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1351 - accuracy: 0.9538 - val_loss: 0.4102 - val_accuracy: 0.8810\n",
      "Epoch 67/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9523 - val_loss: 0.4285 - val_accuracy: 0.8740\n",
      "Epoch 68/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1349 - accuracy: 0.9548 - val_loss: 0.4258 - val_accuracy: 0.8790\n",
      "Epoch 69/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9455 - val_loss: 0.4432 - val_accuracy: 0.8710\n",
      "Epoch 70/150\n",
      "125/125 [==============================] - 0s 3ms/step - loss: 0.1323 - accuracy: 0.9553 - val_loss: 0.4625 - val_accuracy: 0.8730\n",
      "Epoch 71/150\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.1384 - accuracy: 0.9542 - val_loss: 0.4188 - val_accuracy: 0.8830\n",
      "Epoch 72/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1455 - accuracy: 0.9495 - val_loss: 0.4299 - val_accuracy: 0.8820\n",
      "Epoch 73/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1330 - accuracy: 0.9545 - val_loss: 0.4362 - val_accuracy: 0.8770\n",
      "Epoch 74/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1398 - accuracy: 0.9517 - val_loss: 0.4735 - val_accuracy: 0.8710\n",
      "Epoch 75/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1326 - accuracy: 0.9560 - val_loss: 0.4335 - val_accuracy: 0.8790\n",
      "Epoch 76/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.9553 - val_loss: 0.4820 - val_accuracy: 0.8700\n",
      "Epoch 77/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1332 - accuracy: 0.9538 - val_loss: 0.4102 - val_accuracy: 0.8840\n",
      "Epoch 78/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1488 - accuracy: 0.9492 - val_loss: 0.4116 - val_accuracy: 0.8890\n",
      "Epoch 79/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1319 - accuracy: 0.9525 - val_loss: 0.4157 - val_accuracy: 0.8850\n",
      "Epoch 80/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1298 - accuracy: 0.9582 - val_loss: 0.4184 - val_accuracy: 0.8830\n",
      "Epoch 81/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9610 - val_loss: 0.4237 - val_accuracy: 0.8880\n",
      "Epoch 82/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.9620 - val_loss: 0.4159 - val_accuracy: 0.8850\n",
      "Epoch 83/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1333 - accuracy: 0.9550 - val_loss: 0.4357 - val_accuracy: 0.8790\n",
      "Epoch 84/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1258 - accuracy: 0.9560 - val_loss: 0.4239 - val_accuracy: 0.8780\n",
      "Epoch 85/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9565 - val_loss: 0.4206 - val_accuracy: 0.8850\n",
      "Epoch 86/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1300 - accuracy: 0.9555 - val_loss: 0.4342 - val_accuracy: 0.8820\n",
      "Epoch 87/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1329 - accuracy: 0.9548 - val_loss: 0.4180 - val_accuracy: 0.8860\n",
      "Epoch 88/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1230 - accuracy: 0.9613 - val_loss: 0.4306 - val_accuracy: 0.8830\n",
      "Epoch 89/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9553 - val_loss: 0.4221 - val_accuracy: 0.8760\n",
      "Epoch 90/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1388 - accuracy: 0.9517 - val_loss: 0.4206 - val_accuracy: 0.8840\n",
      "Epoch 91/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1296 - accuracy: 0.9588 - val_loss: 0.4360 - val_accuracy: 0.8770\n",
      "Epoch 92/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1231 - accuracy: 0.9600 - val_loss: 0.4258 - val_accuracy: 0.8780\n",
      "Epoch 93/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.9565 - val_loss: 0.4271 - val_accuracy: 0.8840\n",
      "Epoch 94/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1264 - accuracy: 0.9540 - val_loss: 0.4229 - val_accuracy: 0.8900\n",
      "Epoch 95/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9563 - val_loss: 0.4465 - val_accuracy: 0.8760\n",
      "Epoch 96/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1259 - accuracy: 0.9585 - val_loss: 0.4378 - val_accuracy: 0.8820\n",
      "Epoch 97/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9592 - val_loss: 0.4474 - val_accuracy: 0.8790\n",
      "Epoch 98/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1214 - accuracy: 0.9582 - val_loss: 0.4239 - val_accuracy: 0.8770\n",
      "Epoch 99/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1237 - accuracy: 0.9610 - val_loss: 0.4319 - val_accuracy: 0.8780\n",
      "Epoch 100/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9595 - val_loss: 0.4286 - val_accuracy: 0.8830\n",
      "Epoch 101/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1255 - accuracy: 0.9588 - val_loss: 0.4440 - val_accuracy: 0.8750\n",
      "Epoch 102/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.9605 - val_loss: 0.4482 - val_accuracy: 0.8740\n",
      "Epoch 103/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1238 - accuracy: 0.9597 - val_loss: 0.4203 - val_accuracy: 0.8820\n",
      "Epoch 104/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1214 - accuracy: 0.9603 - val_loss: 0.4326 - val_accuracy: 0.8870\n",
      "Epoch 105/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9607 - val_loss: 0.4376 - val_accuracy: 0.8800\n",
      "Epoch 106/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9630 - val_loss: 0.4321 - val_accuracy: 0.8810\n",
      "Epoch 107/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.9580 - val_loss: 0.4705 - val_accuracy: 0.8750\n",
      "Epoch 108/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1235 - accuracy: 0.9582 - val_loss: 0.4252 - val_accuracy: 0.8880\n",
      "Epoch 109/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1161 - accuracy: 0.9645 - val_loss: 0.4637 - val_accuracy: 0.8740\n",
      "Epoch 110/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1221 - accuracy: 0.9588 - val_loss: 0.4410 - val_accuracy: 0.8820\n",
      "Epoch 111/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1182 - accuracy: 0.9570 - val_loss: 0.4432 - val_accuracy: 0.8830\n",
      "Epoch 112/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.9597 - val_loss: 0.4413 - val_accuracy: 0.8810\n",
      "Epoch 113/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1153 - accuracy: 0.9607 - val_loss: 0.4691 - val_accuracy: 0.8720\n",
      "Epoch 114/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1196 - accuracy: 0.9575 - val_loss: 0.4236 - val_accuracy: 0.8850\n",
      "Epoch 115/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.9590 - val_loss: 0.4340 - val_accuracy: 0.8870\n",
      "Epoch 116/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9643 - val_loss: 0.4260 - val_accuracy: 0.8900\n",
      "Epoch 117/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.9610 - val_loss: 0.4579 - val_accuracy: 0.8820\n",
      "Epoch 118/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1169 - accuracy: 0.9617 - val_loss: 0.4237 - val_accuracy: 0.8880\n",
      "Epoch 119/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9635 - val_loss: 0.4358 - val_accuracy: 0.8810\n",
      "Epoch 120/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1205 - accuracy: 0.9590 - val_loss: 0.4404 - val_accuracy: 0.8830\n",
      "Epoch 121/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1127 - accuracy: 0.9643 - val_loss: 0.4297 - val_accuracy: 0.8910\n",
      "Epoch 122/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9615 - val_loss: 0.4613 - val_accuracy: 0.8870\n",
      "Epoch 123/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1187 - accuracy: 0.9628 - val_loss: 0.4592 - val_accuracy: 0.8760\n",
      "Epoch 124/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1152 - accuracy: 0.9635 - val_loss: 0.4348 - val_accuracy: 0.8850\n",
      "Epoch 125/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1167 - accuracy: 0.9632 - val_loss: 0.4836 - val_accuracy: 0.8740\n",
      "Epoch 126/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1191 - accuracy: 0.9580 - val_loss: 0.4485 - val_accuracy: 0.8770\n",
      "Epoch 127/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.9610 - val_loss: 0.4758 - val_accuracy: 0.8760\n",
      "Epoch 128/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1104 - accuracy: 0.9675 - val_loss: 0.4351 - val_accuracy: 0.8820\n",
      "Epoch 129/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9638 - val_loss: 0.4551 - val_accuracy: 0.8880\n",
      "Epoch 130/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1095 - accuracy: 0.9640 - val_loss: 0.4402 - val_accuracy: 0.8800\n",
      "Epoch 131/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1139 - accuracy: 0.9617 - val_loss: 0.4663 - val_accuracy: 0.8770\n",
      "Epoch 132/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1091 - accuracy: 0.9660 - val_loss: 0.4498 - val_accuracy: 0.8850\n",
      "Epoch 133/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1080 - accuracy: 0.9657 - val_loss: 0.4847 - val_accuracy: 0.8740\n",
      "Epoch 134/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.9590 - val_loss: 0.4437 - val_accuracy: 0.8750\n",
      "Epoch 135/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1164 - accuracy: 0.9603 - val_loss: 0.5373 - val_accuracy: 0.8560\n",
      "Epoch 136/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1157 - accuracy: 0.9590 - val_loss: 0.4445 - val_accuracy: 0.8830\n",
      "Epoch 137/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.9622 - val_loss: 0.4353 - val_accuracy: 0.8920\n",
      "Epoch 138/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.9665 - val_loss: 0.4624 - val_accuracy: 0.8880\n",
      "Epoch 139/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1070 - accuracy: 0.9647 - val_loss: 0.4476 - val_accuracy: 0.8840\n",
      "Epoch 140/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1057 - accuracy: 0.9668 - val_loss: 0.4349 - val_accuracy: 0.8880\n",
      "Epoch 141/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.9672 - val_loss: 0.4426 - val_accuracy: 0.8840\n",
      "Epoch 142/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1029 - accuracy: 0.9685 - val_loss: 0.4521 - val_accuracy: 0.8840\n",
      "Epoch 143/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1083 - accuracy: 0.9625 - val_loss: 0.4942 - val_accuracy: 0.8680\n",
      "Epoch 144/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.9640 - val_loss: 0.4723 - val_accuracy: 0.8760\n",
      "Epoch 145/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9645 - val_loss: 0.4632 - val_accuracy: 0.8840\n",
      "Epoch 146/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1039 - accuracy: 0.9657 - val_loss: 0.4800 - val_accuracy: 0.8780\n",
      "Epoch 147/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1063 - accuracy: 0.9640 - val_loss: 0.4519 - val_accuracy: 0.8840\n",
      "Epoch 148/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1073 - accuracy: 0.9647 - val_loss: 0.4717 - val_accuracy: 0.8850\n",
      "Epoch 149/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.9635 - val_loss: 0.4527 - val_accuracy: 0.8880\n",
      "Epoch 150/150\n",
      "125/125 [==============================] - 0s 1ms/step - loss: 0.1136 - accuracy: 0.9610 - val_loss: 0.4492 - val_accuracy: 0.8860\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=150, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "loss = history_dict['loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, acc, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 504us/step - loss: 0.4492 - accuracy: 0.8860\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 504us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0,\n 3,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 2,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 3,\n 0,\n 4,\n 2,\n 3,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 2,\n 3,\n 0,\n 1,\n 1,\n 0,\n 0,\n 3,\n 3,\n 3,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 3,\n 2,\n 2,\n 0,\n 3,\n 3,\n 0,\n 0,\n 0,\n 1,\n 0,\n 1,\n 3,\n 0,\n 4,\n 0,\n 0,\n 0,\n 2,\n 0,\n 4,\n 0,\n 0,\n 2,\n 4,\n 3,\n 0,\n 2,\n 4,\n 3,\n 4,\n 1,\n 3,\n 2,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 2,\n 0,\n 0,\n 1,\n 0,\n 2,\n 3,\n 3,\n 1,\n 4,\n 0,\n 3,\n 0,\n 3,\n 2,\n 4,\n 0,\n 1,\n 0,\n 0,\n 1,\n 0,\n 0,\n 0,\n 2,\n 2,\n 0,\n 0,\n 0,\n 3,\n 0,\n 0,\n 0,\n 2,\n 4,\n 0,\n 1,\n 0,\n 3,\n 1,\n 0,\n 3,\n 0,\n 3,\n 0,\n 3,\n 3,\n 4,\n 0,\n 0,\n 0,\n 2,\n 0,\n 2,\n 1,\n 0,\n 0,\n 1,\n 0,\n 4,\n 2,\n 1,\n 3,\n 0,\n 0,\n 0,\n 1,\n 0,\n 0,\n 2,\n 3,\n 0,\n 1,\n 0,\n 1,\n 0,\n 0,\n 3,\n 1,\n 3,\n 1,\n 1,\n 4,\n 0,\n 0,\n 1,\n 3,\n 0,\n 3,\n 0,\n 1,\n 1,\n 1,\n 1,\n 4,\n 0,\n 4,\n 0,\n 3,\n 2,\n 3,\n 4,\n 0,\n 2,\n 0,\n 2,\n 0,\n 0,\n 0,\n 2,\n 4,\n 2,\n 1,\n 0,\n 3,\n 0,\n 0,\n 4,\n 3,\n 0,\n 0,\n 0,\n 0,\n 3,\n 0,\n 3,\n 3,\n 0,\n 3,\n 0,\n 2,\n 0,\n 4,\n 0,\n 0,\n 0,\n 4,\n 4,\n 1,\n 3,\n 1,\n 0,\n 4,\n 3,\n 1,\n 0,\n 2,\n 3,\n 4,\n 0,\n 3,\n 4,\n 2,\n 1,\n 3,\n 0,\n 0,\n 2,\n 0,\n 2,\n 1,\n 0,\n 0,\n 3,\n 0,\n 0,\n 3,\n 2,\n 1,\n 1,\n 0,\n 0,\n 4,\n 4,\n 0,\n 3,\n 4,\n 0,\n 3,\n 0,\n 1,\n 2,\n 4,\n 2,\n 0,\n 2,\n 0,\n 3,\n 0,\n 3,\n 3,\n 3,\n 0,\n 0,\n 0,\n 3,\n 0,\n 4,\n 1,\n 1,\n 0,\n 0,\n 3,\n 1,\n 4,\n 2,\n 2,\n 2,\n 4,\n 3,\n 3,\n 3,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 3,\n 0,\n 3,\n 2,\n 3,\n 1,\n 3,\n 0,\n 3,\n 4,\n 3,\n 1,\n 3,\n 2,\n 3,\n 0,\n 4,\n 3,\n 4,\n 0,\n 1,\n 2,\n 0,\n 2,\n 0,\n 0,\n 4,\n 2,\n 0,\n 1,\n 0,\n 0,\n 3,\n 0,\n 1,\n 0,\n 3,\n 1,\n 3,\n 0,\n 3,\n 1,\n 3,\n 0,\n 2,\n 0,\n 0,\n 1,\n 0,\n 3,\n 0,\n 0,\n 2,\n 0,\n 0,\n 0,\n 2,\n 4,\n 2,\n 3,\n 0,\n 2,\n 1,\n 0,\n 0,\n 1,\n 0,\n 4,\n 1,\n 3,\n 0,\n 4,\n 3,\n 3,\n 0,\n 2,\n 0,\n 4,\n 0,\n 4,\n 0,\n 1,\n 2,\n 0,\n 1,\n 0,\n 0,\n 1,\n 2,\n 3,\n 0,\n 0,\n 0,\n 0,\n 1,\n 4,\n 0,\n 3,\n 0,\n 2,\n 0,\n 0,\n 3,\n 3,\n 0,\n 3,\n 0,\n 2,\n 1,\n 3,\n 0,\n 0,\n 4,\n 4,\n 2,\n 0,\n 0,\n 0,\n 3,\n 1,\n 1,\n 1,\n 3,\n 0,\n 2,\n 0,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 4,\n 4,\n 0,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 0,\n 0,\n 2,\n 0,\n 0,\n 0,\n 1,\n 0,\n 3,\n 0,\n 3,\n 0,\n 4,\n 1,\n 0,\n 0,\n 0,\n 1,\n 0,\n 2,\n 0,\n 0,\n 1,\n 4,\n 1,\n 3,\n 3,\n 1,\n 3,\n 1,\n 3,\n 1,\n 0,\n 3,\n 0,\n 0,\n 3,\n 2,\n 0,\n 3,\n 0,\n 0,\n 0,\n 3,\n 1,\n 0,\n 2,\n 0,\n 2,\n 3,\n 4,\n 3,\n 2,\n 0,\n 0,\n 2,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 0,\n 2,\n 3,\n 1,\n 3,\n 2,\n 0,\n 2,\n 2,\n 0,\n 3,\n 4,\n 0,\n 0,\n 0,\n 4,\n 1,\n 3,\n 0,\n 0,\n 4,\n 1,\n 1,\n 0,\n 4,\n 3,\n 3,\n 3,\n 0,\n 4,\n 0,\n 3,\n 3,\n 4,\n 1,\n 0,\n 0,\n 3,\n 4,\n 3,\n 3,\n 0,\n 0,\n 1,\n 4,\n 3,\n 0,\n 0,\n 3,\n 3,\n 1,\n 3,\n 3,\n 4,\n 3,\n 0,\n 3,\n 0,\n 3,\n 0,\n 3,\n 0,\n 4,\n 2,\n 3,\n 0,\n 3,\n 0,\n 3,\n 0,\n 0,\n 4,\n 0,\n 3,\n 4,\n 4,\n 3,\n 3,\n 1,\n 1,\n 0,\n 0,\n 2,\n 0,\n 0,\n 2,\n 3,\n 0,\n 3,\n 4,\n 3,\n 3,\n 2,\n 0,\n 3,\n 0,\n 0,\n 0,\n 4,\n 0,\n 1,\n 3,\n 2,\n 1,\n 3,\n 2,\n 0,\n 3,\n 0,\n 4,\n 3,\n 4,\n 3,\n 0,\n 1,\n 3,\n 0,\n 2,\n 4,\n 0,\n 0,\n 1,\n 0,\n 4,\n 1,\n 0,\n 2,\n 3,\n 4,\n 0,\n 3,\n 0,\n 2,\n 1,\n 0,\n 1,\n 0,\n 0,\n 4,\n 0,\n 3,\n 0,\n 0,\n 0,\n 0,\n 3,\n 0,\n 0,\n 1,\n 2,\n 0,\n 4,\n 1,\n 0,\n 0,\n 0,\n 0,\n 0,\n 3,\n 4,\n 2,\n 0,\n 1,\n 0,\n 3,\n 3,\n 0,\n 2,\n 1,\n 1,\n 0,\n 0,\n 0,\n 2,\n 4,\n 0,\n 0,\n 3,\n 0,\n 2,\n 2,\n 2,\n 0,\n 1,\n 3,\n 0,\n 3,\n 3,\n 0,\n 2,\n 1,\n 0,\n 0,\n 1,\n 2,\n 0,\n 0,\n 1,\n 2,\n 0,\n 0,\n 3,\n 3,\n 3,\n 0,\n 3,\n 0,\n 3,\n 0,\n 0,\n 1,\n 4,\n 1,\n 3,\n 3,\n 0,\n 0,\n 2,\n 2,\n 0,\n 1,\n 0,\n 1,\n 1,\n 1,\n 1,\n 0,\n 0,\n 1,\n 3,\n 1,\n 3,\n 4,\n 4,\n 1,\n 3,\n 3,\n 3,\n 2,\n 4,\n 2,\n 1,\n 2,\n 1,\n 0,\n 3,\n 4,\n 0,\n 1,\n 0,\n 3,\n 0,\n 3,\n 2,\n 0,\n 3,\n 0,\n 3,\n 0,\n 2,\n 0,\n 0,\n 2,\n 0,\n 2,\n 0,\n 2,\n 3,\n 0,\n 0,\n 2,\n 4,\n 4,\n 0,\n 0,\n 0,\n 0,\n 2,\n 3,\n 0,\n 3,\n 2,\n 3,\n 3,\n 3,\n 1,\n 0,\n 3,\n 0,\n 3,\n 3,\n 0,\n 0,\n 3,\n 1,\n 4,\n 0,\n 3,\n 2,\n 0,\n 3,\n 4,\n 1,\n 0,\n 3,\n 4,\n 1,\n 0,\n 1,\n 2,\n 4,\n 0,\n 0,\n 3,\n 3,\n 0,\n 2,\n 0,\n 2,\n 0,\n 0,\n 0,\n 0,\n 2,\n 0,\n 3,\n 3,\n 3,\n 0,\n 0,\n 0,\n 4,\n 1,\n 2,\n 0,\n 0,\n 3,\n 0,\n 3,\n 4,\n 0,\n 1,\n 2,\n 3,\n 1,\n 2,\n 0,\n 3,\n 1,\n 4,\n 1,\n 1,\n 0,\n 4,\n 0,\n 0,\n 3,\n 1,\n 4,\n 0,\n 3,\n 0,\n 0,\n 0,\n 0,\n 3,\n 1,\n 4,\n 0,\n 3,\n 4,\n 4,\n 1,\n 0,\n 0,\n 3,\n 2,\n 3,\n 0,\n 3,\n 0,\n 3,\n 0,\n 0,\n 0,\n 0,\n 2,\n 4,\n 3,\n 3,\n 3,\n 0,\n 3,\n 0,\n 2,\n 3,\n 1,\n 4,\n 4,\n 0,\n 0,\n 0,\n 0,\n 0,\n 2,\n 0,\n 0,\n 2,\n 1,\n 1,\n 1,\n 2,\n 1,\n 0,\n 0,\n 4,\n 0,\n 4,\n 0,\n 4,\n 3,\n 0,\n 1,\n 0,\n 0,\n 3,\n 1,\n 3,\n 0,\n 3,\n 4,\n 3,\n 0,\n 1,\n 3,\n 2,\n 4,\n 0,\n 4,\n 0,\n 3,\n 0,\n 3,\n 0,\n 2,\n 2,\n 3,\n 3,\n 1,\n 0,\n 1,\n 3,\n 4,\n 2,\n 4,\n 3,\n 2,\n 0,\n 3,\n 0,\n 3,\n 1,\n 0,\n 2,\n 0,\n 1,\n 2,\n 0,\n 3,\n 3,\n 3,\n 1,\n 2,\n 3,\n 0,\n 0,\n 0,\n 4,\n 2,\n 0,\n 4,\n 4,\n 0,\n 3,\n 0,\n 3]"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicts = model.predict(X_test)\n",
    "\n",
    "categories_predicted = [np.argmax(pred) for pred in predicts]\n",
    "\n",
    "categories_predicted"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "1718    0\n2511    1\n345     1\n2521    0\n54      0\n       ..\n3900    4\n3753    0\n3582    3\n2392    0\n3343    4\nName: incidents, Length: 1000, dtype: int64"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Obter as previsões no dataset de submissão"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "      delay_in_seconds  affected_roads  luminosity  avg_temperature  \\\n0             0.081461        0.142857         0.5         0.464286   \n1             0.000000        0.142857         1.0         0.500000   \n2             0.000000        0.142857         0.5         0.714286   \n3             0.009417        0.285714         0.5         0.571429   \n4             0.000000        0.142857         0.5         0.642857   \n...                ...             ...         ...              ...   \n1201          0.000000        0.142857         0.5         0.357143   \n1202          0.002960        0.142857         1.0         0.785714   \n1203          0.084824        0.142857         0.5         0.392857   \n1204          0.016548        0.142857         0.5         0.464286   \n1205          0.000000        0.142857         0.5         0.607143   \n\n      avg_atm_pressure  avg_humidity  avg_wind_speed  avg_rain  \\\n0              0.59375      0.784946        0.000000       0.0   \n1              0.59375      0.365591        0.222222       0.0   \n2              0.56250      0.688172        0.000000       0.0   \n3              0.28125      0.795699        0.333333       0.0   \n4              0.71875      0.849462        0.000000       0.0   \n...                ...           ...             ...       ...   \n1201           0.81250      0.677419        0.222222       0.0   \n1202           0.53125      0.344086        0.222222       0.0   \n1203           0.59375      0.569892        0.000000       0.0   \n1204           0.50000      0.462366        0.111111       0.0   \n1205           0.71875      0.408602        0.111111       0.0   \n\n      record_date_hour  record_date_day  record_date_month  \\\n0             0.826087         0.400000           0.272727   \n1             0.173913         0.400000           0.818182   \n2             0.826087         0.566667           0.545455   \n3             0.652174         0.966667           0.818182   \n4             0.434783         0.566667           0.818182   \n...                ...              ...                ...   \n1201          0.434783         1.000000           1.000000   \n1202          0.000000         0.500000           0.545455   \n1203          0.652174         0.600000           1.000000   \n1204          0.739130         0.233333           0.181818   \n1205          0.434783         0.166667           0.454545   \n\n      record_date_weekday  \n0                0.166667  \n1                0.333333  \n2                1.000000  \n3                0.833333  \n4                0.000000  \n...                   ...  \n1201             0.666667  \n1202             0.666667  \n1203             1.000000  \n1204             0.000000  \n1205             1.000000  \n\n[1206 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>delay_in_seconds</th>\n      <th>affected_roads</th>\n      <th>luminosity</th>\n      <th>avg_temperature</th>\n      <th>avg_atm_pressure</th>\n      <th>avg_humidity</th>\n      <th>avg_wind_speed</th>\n      <th>avg_rain</th>\n      <th>record_date_hour</th>\n      <th>record_date_day</th>\n      <th>record_date_month</th>\n      <th>record_date_weekday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.081461</td>\n      <td>0.142857</td>\n      <td>0.5</td>\n      <td>0.464286</td>\n      <td>0.59375</td>\n      <td>0.784946</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.826087</td>\n      <td>0.400000</td>\n      <td>0.272727</td>\n      <td>0.166667</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.142857</td>\n      <td>1.0</td>\n      <td>0.500000</td>\n      <td>0.59375</td>\n      <td>0.365591</td>\n      <td>0.222222</td>\n      <td>0.0</td>\n      <td>0.173913</td>\n      <td>0.400000</td>\n      <td>0.818182</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.000000</td>\n      <td>0.142857</td>\n      <td>0.5</td>\n      <td>0.714286</td>\n      <td>0.56250</td>\n      <td>0.688172</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.826087</td>\n      <td>0.566667</td>\n      <td>0.545455</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.009417</td>\n      <td>0.285714</td>\n      <td>0.5</td>\n      <td>0.571429</td>\n      <td>0.28125</td>\n      <td>0.795699</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.652174</td>\n      <td>0.966667</td>\n      <td>0.818182</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.142857</td>\n      <td>0.5</td>\n      <td>0.642857</td>\n      <td>0.71875</td>\n      <td>0.849462</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.434783</td>\n      <td>0.566667</td>\n      <td>0.818182</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1201</th>\n      <td>0.000000</td>\n      <td>0.142857</td>\n      <td>0.5</td>\n      <td>0.357143</td>\n      <td>0.81250</td>\n      <td>0.677419</td>\n      <td>0.222222</td>\n      <td>0.0</td>\n      <td>0.434783</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>1202</th>\n      <td>0.002960</td>\n      <td>0.142857</td>\n      <td>1.0</td>\n      <td>0.785714</td>\n      <td>0.53125</td>\n      <td>0.344086</td>\n      <td>0.222222</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.500000</td>\n      <td>0.545455</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>1203</th>\n      <td>0.084824</td>\n      <td>0.142857</td>\n      <td>0.5</td>\n      <td>0.392857</td>\n      <td>0.59375</td>\n      <td>0.569892</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.652174</td>\n      <td>0.600000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1204</th>\n      <td>0.016548</td>\n      <td>0.142857</td>\n      <td>0.5</td>\n      <td>0.464286</td>\n      <td>0.50000</td>\n      <td>0.462366</td>\n      <td>0.111111</td>\n      <td>0.0</td>\n      <td>0.739130</td>\n      <td>0.233333</td>\n      <td>0.181818</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1205</th>\n      <td>0.000000</td>\n      <td>0.142857</td>\n      <td>0.5</td>\n      <td>0.607143</td>\n      <td>0.71875</td>\n      <td>0.408602</td>\n      <td>0.111111</td>\n      <td>0.0</td>\n      <td>0.434783</td>\n      <td>0.166667</td>\n      <td>0.454545</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1206 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = neural_network_data_preparation(test_df)\n",
    "\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "X_scaled = pd.DataFrame(scaler_X.transform(X[X.columns]), columns=X.columns)\n",
    "\n",
    "X_scaled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 422us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[5.57705838e-33, 1.03291772e-15, 9.39767500e-11, 2.20422262e-05,\n        9.99977887e-01],\n       [9.99352753e-01, 6.47066277e-04, 7.22356930e-08, 6.82782891e-14,\n        6.27919685e-17],\n       [9.99992073e-01, 3.16565047e-06, 4.60154251e-06, 1.88462683e-11,\n        4.76805235e-17],\n       ...,\n       [2.36871340e-08, 9.08942166e-05, 4.46850155e-03, 9.84091461e-01,\n        1.13492105e-02],\n       [1.27998962e-19, 9.27853525e-01, 1.29503580e-02, 2.61129085e-02,\n        3.30830291e-02],\n       [1.94978797e-10, 3.71610440e-07, 3.03487104e-05, 9.99661684e-01,\n        3.07561451e-04]], dtype=float32)"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_prob_predictions = model.predict(X_scaled)\n",
    "\n",
    "categories_prob_predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "[4, 0, 0, 1, 0, 4, 4, 0, 3, 1]"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_predictions = [np.argmax(pred) for pred in categories_prob_predictions]\n",
    "\n",
    "numerical_predictions[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "numerical_predictions_df = pd.DataFrame(numerical_predictions)\n",
    "\n",
    "incidents_categories = {\n",
    "    0: 'None',\n",
    "    1: 'Low',\n",
    "    2: 'Medium',\n",
    "    3: 'High',\n",
    "    4: 'Very_High',\n",
    "}\n",
    "\n",
    "predictions_df = numerical_predictions_df.replace(incidents_categories)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "predictions_df.index += 1\n",
    "\n",
    "predictions_df.to_csv(\"submission.csv\", header=['Incidents'], index_label='RowId')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
