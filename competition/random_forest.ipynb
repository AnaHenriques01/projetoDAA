{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Implementação do Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAINING_DATASET_SOURCE = 'datasets/training_data.csv'  # Since we are one directory up, we should go down one directory to import the datasets\n",
    "TEST_DATASET_SOURCE = 'datasets/test_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from pandas import DataFrame\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "train_df = pd.read_csv(TRAINING_DATASET_SOURCE)\n",
    "test_df = pd.read_csv(TEST_DATASET_SOURCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Definição dos dados de teste e de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['incidents'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#count_class0, count_class1, count_class2, count_class3, count_class4 = train_df['incidents'].value_counts().to_frame()\n",
    "\n",
    "incidents_count = train_df['incidents'].value_counts()\n",
    "\n",
    "max_count = incidents_count.max()\n",
    "\n",
    "print('Max value count:', max_count)\n",
    "\n",
    "df_classes = []\n",
    "for category, counts in zip(incidents_count.index, incidents_count):\n",
    "    #print(category, counts)\n",
    "    df_classes.append(train_df[train_df['incidents'] == category])\n",
    "\n",
    "df_classes_over = []\n",
    "\n",
    "for category in df_classes:\n",
    "    df_classes_over.append(category.sample(max_count, replace=True))\n",
    "\n",
    "df_test_over = pd.concat(df_classes_over, axis=0)\n",
    "\n",
    "print(df_test_over['incidents'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = df_test_over.drop(['incidents'], axis=1)\n",
    "target = df_test_over['incidents']\n",
    "\n",
    "all_features = features.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Obtenção das features numericas e categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropped_columns = ['city_name', 'avg_precipitation', 'magnitude_of_delay', 'record_date']\n",
    "\n",
    "numerical_features = [column for column, dtype in zip(features.columns, features.dtypes)\n",
    "                      if dtype.kind in ['i', 'f'] and column not in dropped_columns]\n",
    "\n",
    "categorical_features = [column for column, dtype in zip(features.columns, features.dtypes)\n",
    "                        if\n",
    "                        dtype.kind not in ['i', 'f'] and column != 'affected_roads' and column not in dropped_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Divisão dos dados em dados de teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Criação de steps para tratar da remoção de features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# noinspection PyPep8Naming,PyMethodMayBeStatic\n",
    "class ColumnsRemovalTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: DataFrame, y=None):\n",
    "        X_ = X.copy()\n",
    "\n",
    "        X_.drop(columns=dropped_columns, inplace=True)\n",
    "\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Criação de steps para tratar da feature `record_date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# noinspection PyPep8Naming,PyMethodMayBeStatic\n",
    "class RecordDateTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: DataFrame, y=None):\n",
    "        X_ = X.copy()\n",
    "\n",
    "        ### Extrair a hora e dia da semana da feature 'record_date'\n",
    "        record_date = pd.DatetimeIndex(X_['record_date'])\n",
    "\n",
    "        X_['hour'] = record_date.hour\n",
    "        X_['day'] = record_date.day\n",
    "        X_['month'] = record_date.month\n",
    "        X_['weekday'] = record_date.weekday\n",
    "\n",
    "        X_.drop(columns=['record_date'], inplace=True)\n",
    "\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        imputer.fit(X_)\n",
    "        X_ = imputer.transform(X_)\n",
    "\n",
    "        scaler.fit(X_)\n",
    "        X_ = scaler.transform(X_)\n",
    "\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Criação de steps para tratar da feature `affected_roads`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# noinspection PyPep8Naming,PyMethodMayBeStatic\n",
    "class AffectedRoadsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: DataFrame, y=None):\n",
    "        X_ = X.copy()\n",
    "\n",
    "        road_quantity = []\n",
    "        for line in X_['affected_roads']:\n",
    "            unique_roads = set(str(line).split(','))\n",
    "            valid_roads = [elem for elem in unique_roads if elem != '']\n",
    "            count = len(valid_roads)\n",
    "            road_quantity.append(count)\n",
    "\n",
    "        X_['num_affected_roads'] = road_quantity\n",
    "        X_.drop(columns=['affected_roads'], inplace=True)\n",
    "\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        scaler = MinMaxScaler()\n",
    "\n",
    "        imputer.fit(X_)\n",
    "        X_ = imputer.transform(X_)\n",
    "\n",
    "        scaler.fit(X_)\n",
    "        X_ = scaler.transform(X_)\n",
    "\n",
    "        return X_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Pipeline de preparação de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (make_pipeline(\n",
    "        AffectedRoadsTransformer()\n",
    "    ), ['affected_roads']),\n",
    "\n",
    "    (make_pipeline(\n",
    "        RecordDateTransformer()\n",
    "    ), ['record_date']),\n",
    "\n",
    "    (make_pipeline(\n",
    "        ColumnsRemovalTransformer()\n",
    "    ), dropped_columns),\n",
    "\n",
    "    (make_pipeline(\n",
    "        SimpleImputer(strategy='median'),\n",
    "        MinMaxScaler(),\n",
    "    ), numerical_features),\n",
    "\n",
    "    (make_pipeline(\n",
    "        SimpleImputer(strategy='constant', fill_value='missing'),\n",
    "        OneHotEncoder(categories='auto', handle_unknown='ignore'),\n",
    "    ), categorical_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocessor.fit(X_train)\n",
    "preprocessor.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold, f_classif\n",
    "\n",
    "preprocessor_best = make_pipeline(preprocessor, VarianceThreshold())#, SelectKBest(f_classif, k='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF_Model = make_pipeline(preprocessor_best, RandomForestClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RF_Model.fit(X_train, y_train)\n",
    "RF_Model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RF_Model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start=10, stop=500, num=5)]\n",
    "\n",
    "max_features = ['sqrt']\n",
    "\n",
    "max_depth = [2, 6, 12, 20, 30, 40, 50]\n",
    "\n",
    "min_samples_split = [2, 5, 30]\n",
    "\n",
    "min_samples_leaf = [1, 2, 50]\n",
    "\n",
    "bootstrap = [True, False]\n",
    "\n",
    "criterions = [\"gini\", \"entropy\", \"log_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': n_estimators,\n",
    "    'randomforestclassifier__max_features': max_features,\n",
    "    'randomforestclassifier__max_depth': max_depth,\n",
    "    'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "    'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "    'randomforestclassifier__bootstrap': bootstrap,\n",
    "    'randomforestclassifier__criterion': criterions\n",
    "}\n",
    "\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.get_scorer_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_RandomGrid = RandomizedSearchCV(estimator=RF_Model, param_distributions=param_grid, cv=20, verbose=1, n_jobs=-1,\n",
    "                                   n_iter=50, scoring='balanced_accuracy', random_state=1000)\n",
    "\n",
    "\n",
    "#rf_RandomGrid = GridSearchCV(estimator=RF_Model, param_grid=param_grid, cv=5, verbose=1, n_jobs=-1, scoring='balanced_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_RandomGrid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_RandomGrid.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_RandomGrid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_RandomGrid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_RandomGrid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_RandomGrid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f'Train: {rf_RandomGrid.score(X_train, y_train):.3f}')\n",
    "print(f'Test: {rf_RandomGrid.score(X_test, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "predictions = rf_RandomGrid.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "# TP FP\n",
    "# FN TN\n",
    "disp = ConfusionMatrixDisplay(cm)\n",
    "\n",
    "disp.plot(cmap='inferno')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Obtenção das previsões do dataset de submissão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = test_df.copy()\n",
    "\n",
    "preprocessor.fit(features)\n",
    "preprocessor.transform(features)\n",
    "\n",
    "predictions = rf_RandomGrid.predict(features)\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df.index += 1\n",
    "predictions_df.to_csv(\"../submission.csv\", header=['Incidents'], index_label='RowId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ddb1a984dc606e8a9c0ef42c41531599b55da58846aaf6b0703a14cafee0a970"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
