{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a83e7540-8165-425f-abbf-583ddd877bc6",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e38320-c91a-4712-8b9c-eddf2614840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pandas import DatetimeIndex\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbbfb26-9509-4f69-a5c0-a0c1b044c3b2",
   "metadata": {},
   "source": [
    "### Carregamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13602a54-0bd6-47a0-a721-480d99fd1c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataOriginal = pd.read_excel('Global_Superstore2.xlsx', index_col=0, comment='#') \n",
    "df = dataOriginal "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a4eacb-28da-4c21-8b59-4e586f7a461c",
   "metadata": {},
   "source": [
    "### Tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4449e9-b7df-4244-b5b0-db7d511db1f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['Ship Mode'] = df['Ship Mode'].astype('category')\n",
    "df['Segment'] = df['Segment'].astype('category')\n",
    "df['City'] = df['Country'].astype('category')\n",
    "df['State'] = df['Country'].astype('category')\n",
    "df['Country'] = df['Country'].astype('category')\n",
    "df['Market'] = df['Market'].astype('category')\n",
    "df['Region'] = df['Region'].astype('category')\n",
    "df['Category'] = df['Category'].astype('category')\n",
    "df['Sub-Category'] = df['Sub-Category'].astype('category')\n",
    "#df['Orde Priority'] = df['Order Priority'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2460c045-5652-47d7-91cb-e662aeb19509",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df['Profit'].isnull().sum() > 0:\n",
    "    df = df[df['Profit'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b673cd5f-b916-46fd-bfb4-08cf25f24421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de valores nulos \n",
      "Order ID          0\n",
      "Order Date        0\n",
      "Ship Date         0\n",
      "Ship Mode         0\n",
      "Customer ID       0\n",
      "Customer Name     0\n",
      "Segment           0\n",
      "City              0\n",
      "State             0\n",
      "Country           0\n",
      "Market            0\n",
      "Region            0\n",
      "Product ID        0\n",
      "Category          0\n",
      "Sub-Category      0\n",
      "Product Name      0\n",
      "Sales             0\n",
      "Quantity          0\n",
      "Discount          0\n",
      "Profit            0\n",
      "Shipping_Cost     0\n",
      "Order_Priority    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Já está justificado no ficheiro data_exploration o porquê de removermos Códigos postais.\n",
    "if 'Postal Code' in df.columns:\n",
    "    df = df.drop('Postal Code', axis=1)\n",
    " \n",
    "\n",
    "df = df.rename(columns = {'Shipping Cost':'Shipping_Cost'})\n",
    "df = df.rename(columns = {'Order Priority':'Order_Priority'})\n",
    "\n",
    "#data['Product Name'] = data['Product Name'].mode().iloc[0]\n",
    "#data.Order_Priority = most_imputer2.fit_transform(data[['Order_Priority']])\n",
    "\n",
    "print(\"Total de valores nulos \")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "172bc32f-6c3c-4a8e-92ec-5b7a3c7e9c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " City 's com mais de 1% de valores\n",
      "\n",
      "Other                 24.707031\n",
      "United States         19.343750\n",
      "Australia              5.541016\n",
      "France                 5.521484\n",
      "Mexico                 5.164062\n",
      "Germany                4.033203\n",
      "China                  3.671875\n",
      "United Kingdom         3.189453\n",
      "Brazil                 3.123047\n",
      "India                  3.037109\n",
      "Indonesia              2.714844\n",
      "Turkey                 2.691406\n",
      "Italy                  2.164062\n",
      "Nigeria                1.767578\n",
      "Spain                  1.677734\n",
      "Dominican Republic     1.449219\n",
      "El Salvador            1.437500\n",
      "Cuba                   1.414062\n",
      "Honduras               1.392578\n",
      "Philippines            1.330078\n",
      "New Zealand            1.226562\n",
      "Nicaragua              1.199219\n",
      "Iran                   1.185547\n",
      "Guatemala              1.017578\n",
      "Name: City, dtype: float64\n",
      "\n",
      " State 's com mais de 1% de valores\n",
      "\n",
      "Other                 24.707031\n",
      "United States         19.343750\n",
      "Australia              5.541016\n",
      "France                 5.521484\n",
      "Mexico                 5.164062\n",
      "Germany                4.033203\n",
      "China                  3.671875\n",
      "United Kingdom         3.189453\n",
      "Brazil                 3.123047\n",
      "India                  3.037109\n",
      "Indonesia              2.714844\n",
      "Turkey                 2.691406\n",
      "Italy                  2.164062\n",
      "Nigeria                1.767578\n",
      "Spain                  1.677734\n",
      "Dominican Republic     1.449219\n",
      "El Salvador            1.437500\n",
      "Cuba                   1.414062\n",
      "Honduras               1.392578\n",
      "Philippines            1.330078\n",
      "New Zealand            1.226562\n",
      "Nicaragua              1.199219\n",
      "Iran                   1.185547\n",
      "Guatemala              1.017578\n",
      "Name: State, dtype: float64\n",
      "\n",
      " Country 's com mais de 1% de valores\n",
      "\n",
      "Other                 24.707031\n",
      "United States         19.343750\n",
      "Australia              5.541016\n",
      "France                 5.521484\n",
      "Mexico                 5.164062\n",
      "Germany                4.033203\n",
      "China                  3.671875\n",
      "United Kingdom         3.189453\n",
      "Brazil                 3.123047\n",
      "India                  3.037109\n",
      "Indonesia              2.714844\n",
      "Turkey                 2.691406\n",
      "Italy                  2.164062\n",
      "Nigeria                1.767578\n",
      "Spain                  1.677734\n",
      "Dominican Republic     1.449219\n",
      "El Salvador            1.437500\n",
      "Cuba                   1.414062\n",
      "Honduras               1.392578\n",
      "Philippines            1.330078\n",
      "New Zealand            1.226562\n",
      "Nicaragua              1.199219\n",
      "Iran                   1.185547\n",
      "Guatemala              1.017578\n",
      "Name: Country, dtype: float64\n",
      "\n",
      " Region 's com mais de 1% de valores\n",
      "\n",
      "Central           21.683594\n",
      "South             12.947266\n",
      "EMEA               9.822266\n",
      "North              9.345703\n",
      "Africa             8.958984\n",
      "Oceania            6.810547\n",
      "West               6.191406\n",
      "Southeast Asia     6.111328\n",
      "East               5.511719\n",
      "North Asia         4.566406\n",
      "Central Asia       4.000000\n",
      "Caribbean          3.300781\n",
      "Name: Region, dtype: float64\n",
      "\n",
      " Sub-Category 's com mais de 1% de valores\n",
      "\n",
      "Binders        12.015625\n",
      "Storage         9.880859\n",
      "Art             9.464844\n",
      "Paper           6.910156\n",
      "Chairs          6.707031\n",
      "Phones          6.556641\n",
      "Furnishings     6.191406\n",
      "Accessories     6.005859\n",
      "Labels          5.089844\n",
      "Supplies        4.736328\n",
      "Fasteners       4.726562\n",
      "Bookcases       4.708984\n",
      "Envelopes       4.652344\n",
      "Copiers         4.341797\n",
      "Appliances      3.427734\n",
      "Machines        2.902344\n",
      "Tables          1.681641\n",
      "Name: Sub-Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def show_frequencies_categorys():\n",
    "    for coluna in df.select_dtypes(exclude=[\"number\",\"bool_\", \"float64\"]).columns:\n",
    "        #print(coluna)\n",
    "        if df[coluna].nunique() > 10 and (\"Date\" not in coluna) and (\"ID\" not in coluna):\n",
    "\n",
    "            \n",
    "            #df2=dfgroupby([coluna])[coluna].sum().rename(\"Courses_fee\").groupby(level = 0).transform(lambda x: x/x.sum())\n",
    "            coluna_percentagens = (df[coluna].value_counts()/df[coluna].count())*100\n",
    "           # print(coluna_percentagens)\n",
    "           # print(\"Exp:\")\n",
    "            values = coluna_percentagens.groupby(coluna_percentagens > 1).filter(lambda x: x.mean() > 1)\n",
    "            if values.size > 0:\n",
    "                print(\"\\n\", coluna, \"'s com mais de 1% de valores\\n\")\n",
    "                print(values)\n",
    "\n",
    "\n",
    "# Juntar países e cidades cuja frequência é menor que uma especificada, para dados categóricos\n",
    "# Esses dados são: \"State\", \"City\", \"Country\", \"Market\", \"Region\"\n",
    "percentage = 1\n",
    "\n",
    "dataset = df\n",
    "for coluna in [\"State\", \"City\", \"Country\", \"Market\", \"Region\" ]:\n",
    "\n",
    "        #print(coluna)\n",
    "        series = dataset.value_counts(dataset[coluna])\n",
    "        mask = (series/series.sum() * 100).lt(percentage)\n",
    "        #print(mask,\"\\n\\n\")\n",
    "        dataset[coluna] = np.where(dataset[coluna].isin(series[mask].index),'Other',dataset[coluna])\n",
    "\n",
    "df = dataset\n",
    "\n",
    "show_frequencies_categorys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e87bdcbd-c90b-44aa-8a67-a916c02b53a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Row ID\n",
      "32298    0.0\n",
      "26341    0.1\n",
      "25330    0.1\n",
      "13524    0.1\n",
      "47221    0.0\n",
      "        ... \n",
      "24175    0.1\n",
      "29002    0.0\n",
      "35398    0.8\n",
      "9596     0.0\n",
      "6147     0.0\n",
      "Name: Discount, Length: 51200, dtype: float64\n",
      "1 0.0\n",
      "2 0.85\n",
      "3 [0.   0.17 0.34 0.51 0.68 0.85]\n",
      "               Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
      "Row ID                                                                        \n",
      "32298    CA-2012-124891  31-07-2012  31-07-2012        Same Day    RH-19495   \n",
      "26341     IN-2013-77878  05-02-2013  07-02-2013    Second Class    JR-16210   \n",
      "25330     IN-2013-71249  17-10-2013  18-10-2013     First Class    CR-12730   \n",
      "13524   ES-2013-1579342  28-01-2013  30-01-2013     First Class    KM-16375   \n",
      "47221      SG-2013-4320  05-11-2013  06-11-2013        Same Day     RH-9495   \n",
      "...                 ...         ...         ...             ...         ...   \n",
      "24175     IN-2014-57662  05-08-2014  10-08-2014  Standard Class    DB-13270   \n",
      "29002     IN-2014-62366  19-06-2014  19-06-2014        Same Day    KE-16420   \n",
      "35398    US-2014-102288  20-06-2014  24-06-2014  Standard Class    ZC-21910   \n",
      "9596     MX-2012-140767  18-02-2012  22-02-2012  Standard Class    RB-19795   \n",
      "6147     MX-2012-134460  22-05-2012  26-05-2012    Second Class    MC-18100   \n",
      "\n",
      "            Customer Name      Segment           City          State  \\\n",
      "Row ID                                                                 \n",
      "32298         Rick Hansen     Consumer  United States  United States   \n",
      "26341       Justin Ritter    Corporate      Australia      Australia   \n",
      "25330        Craig Reiter     Consumer      Australia      Australia   \n",
      "13524    Katherine Murray  Home Office        Germany        Germany   \n",
      "47221         Rick Hansen     Consumer          Other          Other   \n",
      "...                   ...          ...            ...            ...   \n",
      "24175   Deborah Brumfield  Home Office      Australia      Australia   \n",
      "29002     Katrina Edelman    Corporate          Other          Other   \n",
      "35398    Zuschuss Carroll     Consumer  United States  United States   \n",
      "9596           Ross Baird  Home Office         Brazil         Brazil   \n",
      "6147        Mick Crebagga     Consumer      Nicaragua      Nicaragua   \n",
      "\n",
      "              Country  ...        Product ID         Category Sub-Category  \\\n",
      "Row ID                 ...                                                   \n",
      "32298   United States  ...   TEC-AC-10003033       Technology  Accessories   \n",
      "26341       Australia  ...   FUR-CH-10003950        Furniture       Chairs   \n",
      "25330       Australia  ...   TEC-PH-10004664       Technology       Phones   \n",
      "13524         Germany  ...   TEC-PH-10004583       Technology       Phones   \n",
      "47221           Other  ...  TEC-SHA-10000501       Technology      Copiers   \n",
      "...               ...  ...               ...              ...          ...   \n",
      "24175       Australia  ...   OFF-BI-10002424  Office Supplies      Binders   \n",
      "29002           Other  ...   OFF-FA-10000746  Office Supplies    Fasteners   \n",
      "35398   United States  ...   OFF-AP-10002906  Office Supplies   Appliances   \n",
      "9596           Brazil  ...   OFF-BI-10000806  Office Supplies      Binders   \n",
      "6147        Nicaragua  ...   OFF-PA-10004155  Office Supplies        Paper   \n",
      "\n",
      "                                             Product Name     Sales Quantity  \\\n",
      "Row ID                                                                         \n",
      "32298   Plantronics CS510 - Over-the-Head monaural Wir...  2309.650      7.0   \n",
      "26341           Novimex Executive Leather Armchair, Black  3709.395      9.0   \n",
      "25330                   Nokia Smart Phone, with Caller ID  5175.171      9.0   \n",
      "13524                      Motorola Smart Phone, Cordless  2892.510      5.0   \n",
      "47221                      Sharp Wireless Fax, High-Speed  2832.960      8.0   \n",
      "...                                                   ...       ...      ...   \n",
      "24175                               Avery Binder, Economy    58.050      5.0   \n",
      "29002                       Advantus Thumb Tacks, 12 Pack    65.100      5.0   \n",
      "35398   Hoover Replacement Belt for Commercial Guardsm...     0.444      1.0   \n",
      "9596                              Acco Index Tab, Economy    13.440      2.0   \n",
      "6147              Eaton Computer Printout Paper, 8.5 x 11    61.380      3.0   \n",
      "\n",
      "         Discount    Profit Shipping_Cost  Order_Priority  \n",
      "Row ID                                                     \n",
      "32298   0.00-0.17  762.1845        933.57        Critical  \n",
      "26341   0.00-0.17 -288.7650        923.63        Critical  \n",
      "25330   0.00-0.17  919.9710        915.49          Medium  \n",
      "13524   0.00-0.17  -96.5400        910.16          Medium  \n",
      "47221   0.00-0.17  311.5200        903.04        Critical  \n",
      "...           ...       ...           ...             ...  \n",
      "24175   0.00-0.17   19.9500          0.01          Medium  \n",
      "29002   0.00-0.17    4.5000          0.01          Medium  \n",
      "35398   0.68-0.85   -1.1100          0.01          Medium  \n",
      "9596    0.00-0.17    2.4000          0.00          Medium  \n",
      "6147    0.00-0.17    1.8000          0.00            High  \n",
      "\n",
      "[51200 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "data = df\n",
    "number_bins = 6\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "if is_numeric_dtype(data['Discount']):\n",
    "    # Bins in discount\n",
    "    print(\"0 \", data['Discount'])\n",
    "    min_value = data['Discount'].min()\n",
    "    print(\"1\", min_value)\n",
    "    max_value = data['Discount'].max()\n",
    "    print(\"2\", max_value)\n",
    "    limits_bins = np.linspace(min_value,max_value , num=number_bins)\n",
    "    print(\"3\", limits_bins)\n",
    "    labels_names = []\n",
    "    for i in range(0, len(limits_bins) - 1):\n",
    "#    print(\"Olá\")   \n",
    "        v1 = '{:.2f}'.format(limits_bins[i])\n",
    "        v2 = '{:.2f}'.format(limits_bins[i+1])\n",
    "        labels_names.append(f'{v1}-{v2}')\n",
    "    #print(\"v1: \", limits_bins[i])\n",
    "    #print(\"v2: \", limits_bins[i+1])\n",
    "    #print(\"----\")\n",
    "#    data4.loc[data4['score'].between(0, 50, 'both'), 'grade'] = 'C'\n",
    "#print(labels_names)\n",
    "    data['Discount'] = pd.cut(x = data['Discount'], bins = limits_bins, labels = labels_names, include_lowest = True)\n",
    "    print(data)\n",
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a106fce-8abc-4596-9b70-552f88b500e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratar das datas\n",
    "data2 = df\n",
    "\n",
    "if \"Order Date\" in data2:\n",
    "    consider_year = True\n",
    "    consider_month = True\n",
    "    consider_day = True\n",
    "else: \n",
    "    consider_year = False\n",
    "    consider_month = False\n",
    "    consider_day = False\n",
    "    \n",
    "# Converter datas, acho que já está feito em cima, depois confirmar\n",
    "dates_order = DatetimeIndex(pd.to_datetime(data2['Order Date'],format='%d-%m-%Y', errors='coerce'))\n",
    "dates_ship = DatetimeIndex(pd.to_datetime(data2['Ship Date'],format='%d-%m-%Y', errors='coerce'))\n",
    "if consider_year : \n",
    "    data2['Year_order'] = dates_order.year\n",
    "    data2['Year_ship'] = dates_ship.year\n",
    "    \n",
    "if consider_month : \n",
    "    data2['Month_order'] = dates_order.month\n",
    "    data2['Month_ship'] = dates_ship.month\n",
    "\n",
    "if consider_day : \n",
    "    data2['Day_order'] = dates_order.day\n",
    "    data2['Day_ship'] = dates_ship.day\n",
    "if 'Order Date' in data2:\n",
    "    data2 = data2.drop(['Order Date', 'Ship Date'], axis=1)\n",
    "\n",
    "df = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35b4527d-cba4-4178-b230-e676d65f27a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Após fazer Label Encoding\n",
      "               Order ID Ship Mode      Customer Name      Segment  \\\n",
      "Row ID                                                              \n",
      "32298    CA-2012-124891         1        Rick Hansen     Consumer   \n",
      "26341     IN-2013-77878         3      Justin Ritter    Corporate   \n",
      "25330     IN-2013-71249         2       Craig Reiter     Consumer   \n",
      "13524   ES-2013-1579342         2   Katherine Murray  Home Office   \n",
      "47221      SG-2013-4320         1        Rick Hansen     Consumer   \n",
      "...                 ...       ...                ...          ...   \n",
      "24175     IN-2014-57662         4  Deborah Brumfield  Home Office   \n",
      "29002     IN-2014-62366         1    Katrina Edelman    Corporate   \n",
      "35398    US-2014-102288         4   Zuschuss Carroll     Consumer   \n",
      "9596     MX-2012-140767         4         Ross Baird  Home Office   \n",
      "6147     MX-2012-134460         3      Mick Crebagga     Consumer   \n",
      "\n",
      "                 City          State        Country  Market      Region  \\\n",
      "Row ID                                                                    \n",
      "32298   United States  United States  United States      US        East   \n",
      "26341       Australia      Australia      Australia    APAC     Oceania   \n",
      "25330       Australia      Australia      Australia    APAC     Oceania   \n",
      "13524         Germany        Germany        Germany      EU     Central   \n",
      "47221           Other          Other          Other  Africa      Africa   \n",
      "...               ...            ...            ...     ...         ...   \n",
      "24175       Australia      Australia      Australia    APAC     Oceania   \n",
      "29002           Other          Other          Other    APAC  North Asia   \n",
      "35398   United States  United States  United States      US     Central   \n",
      "9596           Brazil         Brazil         Brazil   LATAM       South   \n",
      "6147        Nicaragua      Nicaragua      Nicaragua   LATAM     Central   \n",
      "\n",
      "                                             Product Name  ...  Year_ship  \\\n",
      "Row ID                                                     ...              \n",
      "32298   Plantronics CS510 - Over-the-Head monaural Wir...  ...       2012   \n",
      "26341           Novimex Executive Leather Armchair, Black  ...       2013   \n",
      "25330                   Nokia Smart Phone, with Caller ID  ...       2013   \n",
      "13524                      Motorola Smart Phone, Cordless  ...       2013   \n",
      "47221                      Sharp Wireless Fax, High-Speed  ...       2013   \n",
      "...                                                   ...  ...        ...   \n",
      "24175                               Avery Binder, Economy  ...       2014   \n",
      "29002                       Advantus Thumb Tacks, 12 Pack  ...       2014   \n",
      "35398   Hoover Replacement Belt for Commercial Guardsm...  ...       2014   \n",
      "9596                              Acco Index Tab, Economy  ...       2012   \n",
      "6147              Eaton Computer Printout Paper, 8.5 x 11  ...       2012   \n",
      "\n",
      "        Month_order  Month_ship  Day_order  Day_ship  Product ID LabelEnc  \\\n",
      "Row ID                                                                      \n",
      "32298             7           7         31        31                 8229   \n",
      "26341             2           2          5         7                  907   \n",
      "25330            10          10         17        18                10140   \n",
      "13524             1           1         28        30                10129   \n",
      "47221            11          11          5         6                10232   \n",
      "...             ...         ...        ...       ...                  ...   \n",
      "24175             8           8          5        10                 3683   \n",
      "29002             6           6         19        19                 4793   \n",
      "35398             6           6         20        24                 2622   \n",
      "9596              2           2         18        22                 3484   \n",
      "6147              5           5         22        26                 6546   \n",
      "\n",
      "        Costumer ID LabelEnc  Category LabelEnc  Sub-Category LabelEnc  \\\n",
      "Row ID                                                                   \n",
      "32298                   1286                  2                      0   \n",
      "26341                    808                  0                      5   \n",
      "25330                    336                  2                     13   \n",
      "13524                    873                  2                     13   \n",
      "47221                   1290                  2                      6   \n",
      "...                      ...                ...                    ...   \n",
      "24175                    383                  1                      3   \n",
      "29002                    854                  1                      8   \n",
      "35398                   1587                  1                      1   \n",
      "9596                    1249                  1                      3   \n",
      "6147                     981                  1                     12   \n",
      "\n",
      "        Discount LabelEnc  \n",
      "Row ID                     \n",
      "32298                   0  \n",
      "26341                   0  \n",
      "25330                   0  \n",
      "13524                   0  \n",
      "47221                   0  \n",
      "...                   ...  \n",
      "24175                   0  \n",
      "29002                   0  \n",
      "35398                   4  \n",
      "9596                    0  \n",
      "6147                    0  \n",
      "\n",
      "[51200 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Label encoding de algumas variáveis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "if \"Category\" in data2:\n",
    "    process_Product_ID = True\n",
    "    process_Costumer_ID = True\n",
    "    process_Category = True\n",
    "    process_Sub_Category = True\n",
    "    process_Discount = True\n",
    "else: \n",
    "    process_Product_ID = False\n",
    "    process_Costumer_ID = False\n",
    "    process_Category = False\n",
    "    process_Sub_Category = False\n",
    "    process_Discount = False\n",
    "\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "if process_Product_ID:\n",
    "    data2[\"Product ID LabelEnc\"] = lb_make.fit_transform(data2[\"Product ID\"])\n",
    "\n",
    "if process_Costumer_ID:\n",
    "    data2[\"Costumer ID LabelEnc\"] = lb_make.fit_transform(data2[\"Customer ID\"])\n",
    "\n",
    "if process_Category:\n",
    "    data2[\"Category LabelEnc\"] = lb_make.fit_transform(data2[\"Category\"])\n",
    "\n",
    "if process_Sub_Category:\n",
    "    data2[\"Sub-Category LabelEnc\"] = lb_make.fit_transform(data2[\"Sub-Category\"])\n",
    "if process_Discount:\n",
    "    data2[\"Discount LabelEnc\"] = lb_make.fit_transform(data2[\"Discount\"])\n",
    "\n",
    "    \n",
    "if process_Product_ID: \n",
    "    data2 = data2.drop(['Product ID', 'Customer ID', \"Category\", \"Sub-Category\", \"Discount\"], axis=1)\n",
    "#from pandas.api.types import is_string_dtype\n",
    "\n",
    "if data2['Ship Mode'].dtype == 'category' or data2['Ship Mode'].dtype == 'object':\n",
    "   # print(\"Ship mode ainda está em categorias\")\n",
    "    #print(data2['Ship Mode'].unique())\n",
    "    ship_mode_dic = {'Same Day':1, 'First Class':2, 'Second Class':3,'Standard Class':4}\n",
    "    #dataTemp = pd.DataFrame({\"Ship Mode\": ship_mode_dic.keys()})\n",
    "    #print(\"Aqui vai\\n\")\n",
    "    data2[\"Ship Mode\"]= data2[\"Ship Mode\"].apply(lambda x: ship_mode_dic.get(x))\n",
    "    #print(data2)\n",
    "\n",
    "if \"Order_Priority\" in data2 and (data2['Order_Priority'].dtype == 'category' or data2['Order_Priority'].dtype == 'object'):\n",
    "    dataTemp = data2\n",
    "    # print(\"Ship mode ainda está em categorias\")\n",
    "    #print(dataTemp['Order_Priority'].unique())\n",
    "    priorities_dic = {'Critical':1, 'High':2, 'Medium':3,'Low':4}\n",
    "    #dataTemp = pd.DataFrame({\"Order_Priority\": priorities_dic.keys()})\n",
    "    #print(\"Aqui vai\\n\")\n",
    "    dataTemp[\"Order_Priority\"]= dataTemp[\"Order_Priority\"].apply(lambda x: priorities_dic.get(x))\n",
    "    #print(dataTemp.info())\n",
    "    data2 = dataTemp\n",
    "    \n",
    "print(\"\\nApós fazer Label Encoding\")\n",
    "print(data2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c284a5d-b90a-4826-9d25-6710efbd0fe2",
   "metadata": {},
   "source": [
    "### Modelo de Árvore de decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51d50e02-e35f-4df5-967b-a32dad87ef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df\n",
    "dataset = dataset.drop(columns=['Quantity', 'Discount', 'Shipping_Cost', 'Sales'])\n",
    "#print(dataset)\n",
    "\n",
    "#print(dataset.info())\n",
    "X = dataset.drop(['Profit'],axis=1)\n",
    "y = dataset['Profit']\n",
    "\n",
    "X = dataset.drop(['Profit', 'Order ID', 'Customer Name', 'Product Name','Region', 'City'], axis=1)\n",
    "\n",
    "if 'Order Priority' in X:\n",
    "    X = X.drop(['Order Priority', 'Market', \"Country\", \"State\", \"Segment\", \"Ship Mode\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59ba07f6-2a0a-4710-ae7f-50cc038beff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fe04b99-1536-43bd-87b0-6f2bbf8bb5c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Standard Class'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 35>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m     X_train_transformed[coisa] \u001b[38;5;241m=\u001b[39m lb_make\u001b[38;5;241m.\u001b[39mfit_transform(X_train[coisa]) \n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# X_train_transformed = lb_make.fit_transform(X_train)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#X_train = X_train.filter(['Quantity'])\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m predictions \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m ):\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:165\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    163\u001b[0m check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    164\u001b[0m check_y_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 165\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_separately\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcheck_X_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_y_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[0;32m    169\u001b[0m     X\u001b[38;5;241m.\u001b[39msort_indices()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:578\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate_separately:\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;66;03m# We need this because some estimators validate X and y\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;66;03m# separately, and in general, separately calling check_array()\u001b[39;00m\n\u001b[0;32m    575\u001b[0m     \u001b[38;5;66;03m# on X and y isn't equivalent to just calling check_X_y()\u001b[39;00m\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;66;03m# :(\u001b[39;00m\n\u001b[0;32m    577\u001b[0m     check_X_params, check_y_params \u001b[38;5;241m=\u001b[39m validate_separately\n\u001b[1;32m--> 578\u001b[0m     X \u001b[38;5;241m=\u001b[39m check_array(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_X_params)\n\u001b[0;32m    579\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    744\u001b[0m         array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(dtype, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 746\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    750\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: npt\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m-> 2064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Standard Class'"
     ]
    }
   ],
   "source": [
    "#X_train1 = X_train[X_train.isna().any(axis=1)]\n",
    "\"\"\"\n",
    "\n",
    "#Acho que podemos converter os mais importantes para one-hot enconding ou algo do género. Depois continuo\n",
    "print(\"Será que há Na\\n\")\n",
    "count = np.isnan(X_train).values.sum()\n",
    "count = np.isnan(X_train).any()\n",
    "print(\"\\nX -> It contains \" + str(count) + \" nan values\\n\")\n",
    "count = np.isnan(y_train).values.sum()\n",
    "print(\"Y -> It contains \" + str(count) + \" nan values\")\n",
    "print(\"Será que há Inf\")\n",
    "\n",
    "count = np.isinf(X_train).values.sum()\n",
    "print(\"X -> It contains \" + str(count) + \" infinite values\")\n",
    "count = np.isinf(y_train).values.sum()\n",
    "print(\"Y -> It contains \" + str(count) + \" infinite values\")\n",
    "\n",
    "print(X.info())\n",
    "print(y.info())\n",
    "\"\"\"\n",
    "# Para este\n",
    "y_train = y_train.astype(int)\n",
    "y_train_transformed = lb_make.fit_transform(y_train)\n",
    "\n",
    "# Análise de variáveis que são do tipo float, para descobrir se é necessário multiplicar para não se perder informação na conversão para int.\n",
    "X_train_transformed = {}\n",
    "for coisa in X_train:\n",
    "    #print(X_train[coisa])\n",
    "    X_train_transformed[coisa] = lb_make.fit_transform(X_train[coisa]) \n",
    "# X_train_transformed = lb_make.fit_transform(X_train)\n",
    "\n",
    "\n",
    "#X_train = X_train.filter(['Quantity'])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#scores = cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd5bf9-c2ce-46da-b142-9d9a8bc0b558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas\n",
    "print(mean_absolute_error(y_test, predictions))\n",
    "print(mean_squared_error(y_test, predictions, squared=True))\n",
    "print(mean_squared_error(y_test, predictions, squared=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
