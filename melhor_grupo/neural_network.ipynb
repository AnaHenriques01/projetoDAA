{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b856b60-22f2-493e-a91d-83c3b4bc68d7",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5f0dbd9-a10f-4a55-9b16-d6ff09fae607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pandas import DatetimeIndex\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2edeaf-98b3-452e-a88b-8daa1d68f226",
   "metadata": {},
   "source": [
    "### Carregamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20203651-46ed-4cf0-bdd3-20d4e6c8ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataOriginal = pd.read_excel('Global_Superstore2.xlsx', index_col=0, comment='#') \n",
    "df = dataOriginal "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790805ff-ab09-4658-b9f5-f5a04542bc49",
   "metadata": {},
   "source": [
    "### Tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05895e64-b95c-4dc1-9a4f-88c0c178ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ship Mode'] = df['Ship Mode'].astype('category')\n",
    "df['Segment'] = df['Segment'].astype('category')\n",
    "df['City'] = df['Country'].astype('category')\n",
    "df['State'] = df['Country'].astype('category')\n",
    "df['Country'] = df['Country'].astype('category')\n",
    "df['Market'] = df['Market'].astype('category')\n",
    "df['Region'] = df['Region'].astype('category')\n",
    "df['Category'] = df['Category'].astype('category')\n",
    "df['Sub-Category'] = df['Sub-Category'].astype('category')\n",
    "#df['Orde Priority'] = df['Order Priority'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50d5ec20-1efb-49d6-b7f2-e97c21d32fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df['Profit'].isnull().sum() > 0:\n",
    "    df = df[df['Profit'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "864a5881-bfa7-4904-9eca-5b058354e746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de valores nulos \n",
      "Order ID          0\n",
      "Order Date        0\n",
      "Ship Date         0\n",
      "Ship Mode         0\n",
      "Customer ID       0\n",
      "Customer Name     0\n",
      "Segment           0\n",
      "City              0\n",
      "State             0\n",
      "Country           0\n",
      "Market            0\n",
      "Region            0\n",
      "Product ID        0\n",
      "Category          0\n",
      "Sub-Category      0\n",
      "Product Name      0\n",
      "Sales             0\n",
      "Quantity          0\n",
      "Discount          0\n",
      "Profit            0\n",
      "Shipping_Cost     0\n",
      "Order_Priority    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Já está justificado no ficheiro data_exploration o porquê de removermos Códigos postais.\n",
    "if 'Postal Code' in df.columns:\n",
    "    df = df.drop('Postal Code', axis=1)\n",
    " \n",
    "\n",
    "df = df.rename(columns = {'Shipping Cost':'Shipping_Cost'})\n",
    "df = df.rename(columns = {'Order Priority':'Order_Priority'})\n",
    "\n",
    "#data['Product Name'] = data['Product Name'].mode().iloc[0]\n",
    "#data.Order_Priority = most_imputer2.fit_transform(data[['Order_Priority']])\n",
    "\n",
    "print(\"Total de valores nulos \")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6247bd9f-90e6-4b22-b8c0-6f0a4a1420ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " City 's com mais de 1% de valores\n",
      "\n",
      "Other                 24.707031\n",
      "United States         19.343750\n",
      "Australia              5.541016\n",
      "France                 5.521484\n",
      "Mexico                 5.164062\n",
      "Germany                4.033203\n",
      "China                  3.671875\n",
      "United Kingdom         3.189453\n",
      "Brazil                 3.123047\n",
      "India                  3.037109\n",
      "Indonesia              2.714844\n",
      "Turkey                 2.691406\n",
      "Italy                  2.164062\n",
      "Nigeria                1.767578\n",
      "Spain                  1.677734\n",
      "Dominican Republic     1.449219\n",
      "El Salvador            1.437500\n",
      "Cuba                   1.414062\n",
      "Honduras               1.392578\n",
      "Philippines            1.330078\n",
      "New Zealand            1.226562\n",
      "Nicaragua              1.199219\n",
      "Iran                   1.185547\n",
      "Guatemala              1.017578\n",
      "Name: City, dtype: float64\n",
      "\n",
      " State 's com mais de 1% de valores\n",
      "\n",
      "Other                 24.707031\n",
      "United States         19.343750\n",
      "Australia              5.541016\n",
      "France                 5.521484\n",
      "Mexico                 5.164062\n",
      "Germany                4.033203\n",
      "China                  3.671875\n",
      "United Kingdom         3.189453\n",
      "Brazil                 3.123047\n",
      "India                  3.037109\n",
      "Indonesia              2.714844\n",
      "Turkey                 2.691406\n",
      "Italy                  2.164062\n",
      "Nigeria                1.767578\n",
      "Spain                  1.677734\n",
      "Dominican Republic     1.449219\n",
      "El Salvador            1.437500\n",
      "Cuba                   1.414062\n",
      "Honduras               1.392578\n",
      "Philippines            1.330078\n",
      "New Zealand            1.226562\n",
      "Nicaragua              1.199219\n",
      "Iran                   1.185547\n",
      "Guatemala              1.017578\n",
      "Name: State, dtype: float64\n",
      "\n",
      " Country 's com mais de 1% de valores\n",
      "\n",
      "Other                 24.707031\n",
      "United States         19.343750\n",
      "Australia              5.541016\n",
      "France                 5.521484\n",
      "Mexico                 5.164062\n",
      "Germany                4.033203\n",
      "China                  3.671875\n",
      "United Kingdom         3.189453\n",
      "Brazil                 3.123047\n",
      "India                  3.037109\n",
      "Indonesia              2.714844\n",
      "Turkey                 2.691406\n",
      "Italy                  2.164062\n",
      "Nigeria                1.767578\n",
      "Spain                  1.677734\n",
      "Dominican Republic     1.449219\n",
      "El Salvador            1.437500\n",
      "Cuba                   1.414062\n",
      "Honduras               1.392578\n",
      "Philippines            1.330078\n",
      "New Zealand            1.226562\n",
      "Nicaragua              1.199219\n",
      "Iran                   1.185547\n",
      "Guatemala              1.017578\n",
      "Name: Country, dtype: float64\n",
      "\n",
      " Region 's com mais de 1% de valores\n",
      "\n",
      "Central           21.683594\n",
      "South             12.947266\n",
      "EMEA               9.822266\n",
      "North              9.345703\n",
      "Africa             8.958984\n",
      "Oceania            6.810547\n",
      "West               6.191406\n",
      "Southeast Asia     6.111328\n",
      "East               5.511719\n",
      "North Asia         4.566406\n",
      "Central Asia       4.000000\n",
      "Caribbean          3.300781\n",
      "Name: Region, dtype: float64\n",
      "\n",
      " Sub-Category 's com mais de 1% de valores\n",
      "\n",
      "Binders        12.015625\n",
      "Storage         9.880859\n",
      "Art             9.464844\n",
      "Paper           6.910156\n",
      "Chairs          6.707031\n",
      "Phones          6.556641\n",
      "Furnishings     6.191406\n",
      "Accessories     6.005859\n",
      "Labels          5.089844\n",
      "Supplies        4.736328\n",
      "Fasteners       4.726562\n",
      "Bookcases       4.708984\n",
      "Envelopes       4.652344\n",
      "Copiers         4.341797\n",
      "Appliances      3.427734\n",
      "Machines        2.902344\n",
      "Tables          1.681641\n",
      "Name: Sub-Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def show_frequencies_categorys():\n",
    "    for coluna in df.select_dtypes(exclude=[\"number\",\"bool_\", \"float64\"]).columns:\n",
    "        #print(coluna)\n",
    "        if df[coluna].nunique() > 10 and (\"Date\" not in coluna) and (\"ID\" not in coluna):\n",
    "\n",
    "            \n",
    "            #df2=dfgroupby([coluna])[coluna].sum().rename(\"Courses_fee\").groupby(level = 0).transform(lambda x: x/x.sum())\n",
    "            coluna_percentagens = (df[coluna].value_counts()/df[coluna].count())*100\n",
    "           # print(coluna_percentagens)\n",
    "           # print(\"Exp:\")\n",
    "            values = coluna_percentagens.groupby(coluna_percentagens > 1).filter(lambda x: x.mean() > 1)\n",
    "            if values.size > 0:\n",
    "                print(\"\\n\", coluna, \"'s com mais de 1% de valores\\n\")\n",
    "                print(values)\n",
    "\n",
    "\n",
    "# Juntar países e cidades cuja frequência é menor que uma especificada, para dados categóricos\n",
    "# Esses dados são: \"State\", \"City\", \"Country\", \"Market\", \"Region\"\n",
    "percentage = 1\n",
    "\n",
    "dataset = df\n",
    "for coluna in [\"State\", \"City\", \"Country\", \"Market\", \"Region\" ]:\n",
    "\n",
    "        #print(coluna)\n",
    "        series = dataset.value_counts(dataset[coluna])\n",
    "        mask = (series/series.sum() * 100).lt(percentage)\n",
    "        #print(mask,\"\\n\\n\")\n",
    "        dataset[coluna] = np.where(dataset[coluna].isin(series[mask].index),'Other',dataset[coluna])\n",
    "\n",
    "df = dataset\n",
    "\n",
    "show_frequencies_categorys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5532b3e2-a0d3-4c1d-a014-71d627738184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Row ID\n",
      "32298    0.0\n",
      "26341    0.1\n",
      "25330    0.1\n",
      "13524    0.1\n",
      "47221    0.0\n",
      "        ... \n",
      "24175    0.1\n",
      "29002    0.0\n",
      "35398    0.8\n",
      "9596     0.0\n",
      "6147     0.0\n",
      "Name: Discount, Length: 51200, dtype: float64\n",
      "1 0.0\n",
      "2 0.85\n",
      "3 [0.   0.17 0.34 0.51 0.68 0.85]\n",
      "               Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
      "Row ID                                                                        \n",
      "32298    CA-2012-124891  31-07-2012  31-07-2012        Same Day    RH-19495   \n",
      "26341     IN-2013-77878  05-02-2013  07-02-2013    Second Class    JR-16210   \n",
      "25330     IN-2013-71249  17-10-2013  18-10-2013     First Class    CR-12730   \n",
      "13524   ES-2013-1579342  28-01-2013  30-01-2013     First Class    KM-16375   \n",
      "47221      SG-2013-4320  05-11-2013  06-11-2013        Same Day     RH-9495   \n",
      "...                 ...         ...         ...             ...         ...   \n",
      "24175     IN-2014-57662  05-08-2014  10-08-2014  Standard Class    DB-13270   \n",
      "29002     IN-2014-62366  19-06-2014  19-06-2014        Same Day    KE-16420   \n",
      "35398    US-2014-102288  20-06-2014  24-06-2014  Standard Class    ZC-21910   \n",
      "9596     MX-2012-140767  18-02-2012  22-02-2012  Standard Class    RB-19795   \n",
      "6147     MX-2012-134460  22-05-2012  26-05-2012    Second Class    MC-18100   \n",
      "\n",
      "            Customer Name      Segment           City          State  \\\n",
      "Row ID                                                                 \n",
      "32298         Rick Hansen     Consumer  United States  United States   \n",
      "26341       Justin Ritter    Corporate      Australia      Australia   \n",
      "25330        Craig Reiter     Consumer      Australia      Australia   \n",
      "13524    Katherine Murray  Home Office        Germany        Germany   \n",
      "47221         Rick Hansen     Consumer          Other          Other   \n",
      "...                   ...          ...            ...            ...   \n",
      "24175   Deborah Brumfield  Home Office      Australia      Australia   \n",
      "29002     Katrina Edelman    Corporate          Other          Other   \n",
      "35398    Zuschuss Carroll     Consumer  United States  United States   \n",
      "9596           Ross Baird  Home Office         Brazil         Brazil   \n",
      "6147        Mick Crebagga     Consumer      Nicaragua      Nicaragua   \n",
      "\n",
      "              Country  ...        Product ID         Category Sub-Category  \\\n",
      "Row ID                 ...                                                   \n",
      "32298   United States  ...   TEC-AC-10003033       Technology  Accessories   \n",
      "26341       Australia  ...   FUR-CH-10003950        Furniture       Chairs   \n",
      "25330       Australia  ...   TEC-PH-10004664       Technology       Phones   \n",
      "13524         Germany  ...   TEC-PH-10004583       Technology       Phones   \n",
      "47221           Other  ...  TEC-SHA-10000501       Technology      Copiers   \n",
      "...               ...  ...               ...              ...          ...   \n",
      "24175       Australia  ...   OFF-BI-10002424  Office Supplies      Binders   \n",
      "29002           Other  ...   OFF-FA-10000746  Office Supplies    Fasteners   \n",
      "35398   United States  ...   OFF-AP-10002906  Office Supplies   Appliances   \n",
      "9596           Brazil  ...   OFF-BI-10000806  Office Supplies      Binders   \n",
      "6147        Nicaragua  ...   OFF-PA-10004155  Office Supplies        Paper   \n",
      "\n",
      "                                             Product Name     Sales Quantity  \\\n",
      "Row ID                                                                         \n",
      "32298   Plantronics CS510 - Over-the-Head monaural Wir...  2309.650      7.0   \n",
      "26341           Novimex Executive Leather Armchair, Black  3709.395      9.0   \n",
      "25330                   Nokia Smart Phone, with Caller ID  5175.171      9.0   \n",
      "13524                      Motorola Smart Phone, Cordless  2892.510      5.0   \n",
      "47221                      Sharp Wireless Fax, High-Speed  2832.960      8.0   \n",
      "...                                                   ...       ...      ...   \n",
      "24175                               Avery Binder, Economy    58.050      5.0   \n",
      "29002                       Advantus Thumb Tacks, 12 Pack    65.100      5.0   \n",
      "35398   Hoover Replacement Belt for Commercial Guardsm...     0.444      1.0   \n",
      "9596                              Acco Index Tab, Economy    13.440      2.0   \n",
      "6147              Eaton Computer Printout Paper, 8.5 x 11    61.380      3.0   \n",
      "\n",
      "         Discount    Profit Shipping_Cost  Order_Priority  \n",
      "Row ID                                                     \n",
      "32298   0.00-0.17  762.1845        933.57        Critical  \n",
      "26341   0.00-0.17 -288.7650        923.63        Critical  \n",
      "25330   0.00-0.17  919.9710        915.49          Medium  \n",
      "13524   0.00-0.17  -96.5400        910.16          Medium  \n",
      "47221   0.00-0.17  311.5200        903.04        Critical  \n",
      "...           ...       ...           ...             ...  \n",
      "24175   0.00-0.17   19.9500          0.01          Medium  \n",
      "29002   0.00-0.17    4.5000          0.01          Medium  \n",
      "35398   0.68-0.85   -1.1100          0.01          Medium  \n",
      "9596    0.00-0.17    2.4000          0.00          Medium  \n",
      "6147    0.00-0.17    1.8000          0.00            High  \n",
      "\n",
      "[51200 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "data = df\n",
    "number_bins = 6\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "if is_numeric_dtype(data['Discount']):\n",
    "    # Bins in discount\n",
    "    print(\"0 \", data['Discount'])\n",
    "    min_value = data['Discount'].min()\n",
    "    print(\"1\", min_value)\n",
    "    max_value = data['Discount'].max()\n",
    "    print(\"2\", max_value)\n",
    "    limits_bins = np.linspace(min_value,max_value , num=number_bins)\n",
    "    print(\"3\", limits_bins)\n",
    "    labels_names = []\n",
    "    for i in range(0, len(limits_bins) - 1):\n",
    "#    print(\"Olá\")   \n",
    "        v1 = '{:.2f}'.format(limits_bins[i])\n",
    "        v2 = '{:.2f}'.format(limits_bins[i+1])\n",
    "        labels_names.append(f'{v1}-{v2}')\n",
    "    #print(\"v1: \", limits_bins[i])\n",
    "    #print(\"v2: \", limits_bins[i+1])\n",
    "    #print(\"----\")\n",
    "#    data4.loc[data4['score'].between(0, 50, 'both'), 'grade'] = 'C'\n",
    "#print(labels_names)\n",
    "    data['Discount'] = pd.cut(x = data['Discount'], bins = limits_bins, labels = labels_names, include_lowest = True)\n",
    "    print(data)\n",
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d579766-e8f4-4699-b3fd-069fab896bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratar das datas\n",
    "data2 = df\n",
    "\n",
    "if \"Order Date\" in data2:\n",
    "    consider_year = True\n",
    "    consider_month = True\n",
    "    consider_day = True\n",
    "else: \n",
    "    consider_year = False\n",
    "    consider_month = False\n",
    "    consider_day = False\n",
    "    \n",
    "# Converter datas, acho que já está feito em cima, depois confirmar\n",
    "dates_order = DatetimeIndex(pd.to_datetime(data2['Order Date'],format='%d-%m-%Y', errors='coerce'))\n",
    "dates_ship = DatetimeIndex(pd.to_datetime(data2['Ship Date'],format='%d-%m-%Y', errors='coerce'))\n",
    "if consider_year : \n",
    "    data2['Year_order'] = dates_order.year\n",
    "    data2['Year_ship'] = dates_ship.year\n",
    "    \n",
    "if consider_month : \n",
    "    data2['Month_order'] = dates_order.month\n",
    "    data2['Month_ship'] = dates_ship.month\n",
    "\n",
    "if consider_day : \n",
    "    data2['Day_order'] = dates_order.day\n",
    "    data2['Day_ship'] = dates_ship.day\n",
    "if 'Order Date' in data2:\n",
    "    data2 = data2.drop(['Order Date', 'Ship Date'], axis=1)\n",
    "\n",
    "df = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a4e133e-7973-4bc3-84d1-6c1aa781e21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Após fazer Label Encoding\n",
      "               Order ID Ship Mode      Customer Name      Segment  \\\n",
      "Row ID                                                              \n",
      "32298    CA-2012-124891         1        Rick Hansen     Consumer   \n",
      "26341     IN-2013-77878         3      Justin Ritter    Corporate   \n",
      "25330     IN-2013-71249         2       Craig Reiter     Consumer   \n",
      "13524   ES-2013-1579342         2   Katherine Murray  Home Office   \n",
      "47221      SG-2013-4320         1        Rick Hansen     Consumer   \n",
      "...                 ...       ...                ...          ...   \n",
      "24175     IN-2014-57662         4  Deborah Brumfield  Home Office   \n",
      "29002     IN-2014-62366         1    Katrina Edelman    Corporate   \n",
      "35398    US-2014-102288         4   Zuschuss Carroll     Consumer   \n",
      "9596     MX-2012-140767         4         Ross Baird  Home Office   \n",
      "6147     MX-2012-134460         3      Mick Crebagga     Consumer   \n",
      "\n",
      "                 City          State        Country  Market      Region  \\\n",
      "Row ID                                                                    \n",
      "32298   United States  United States  United States      US        East   \n",
      "26341       Australia      Australia      Australia    APAC     Oceania   \n",
      "25330       Australia      Australia      Australia    APAC     Oceania   \n",
      "13524         Germany        Germany        Germany      EU     Central   \n",
      "47221           Other          Other          Other  Africa      Africa   \n",
      "...               ...            ...            ...     ...         ...   \n",
      "24175       Australia      Australia      Australia    APAC     Oceania   \n",
      "29002           Other          Other          Other    APAC  North Asia   \n",
      "35398   United States  United States  United States      US     Central   \n",
      "9596           Brazil         Brazil         Brazil   LATAM       South   \n",
      "6147        Nicaragua      Nicaragua      Nicaragua   LATAM     Central   \n",
      "\n",
      "                                             Product Name  ...  Year_ship  \\\n",
      "Row ID                                                     ...              \n",
      "32298   Plantronics CS510 - Over-the-Head monaural Wir...  ...       2012   \n",
      "26341           Novimex Executive Leather Armchair, Black  ...       2013   \n",
      "25330                   Nokia Smart Phone, with Caller ID  ...       2013   \n",
      "13524                      Motorola Smart Phone, Cordless  ...       2013   \n",
      "47221                      Sharp Wireless Fax, High-Speed  ...       2013   \n",
      "...                                                   ...  ...        ...   \n",
      "24175                               Avery Binder, Economy  ...       2014   \n",
      "29002                       Advantus Thumb Tacks, 12 Pack  ...       2014   \n",
      "35398   Hoover Replacement Belt for Commercial Guardsm...  ...       2014   \n",
      "9596                              Acco Index Tab, Economy  ...       2012   \n",
      "6147              Eaton Computer Printout Paper, 8.5 x 11  ...       2012   \n",
      "\n",
      "        Month_order  Month_ship  Day_order  Day_ship  Product ID LabelEnc  \\\n",
      "Row ID                                                                      \n",
      "32298             7           7         31        31                 8229   \n",
      "26341             2           2          5         7                  907   \n",
      "25330            10          10         17        18                10140   \n",
      "13524             1           1         28        30                10129   \n",
      "47221            11          11          5         6                10232   \n",
      "...             ...         ...        ...       ...                  ...   \n",
      "24175             8           8          5        10                 3683   \n",
      "29002             6           6         19        19                 4793   \n",
      "35398             6           6         20        24                 2622   \n",
      "9596              2           2         18        22                 3484   \n",
      "6147              5           5         22        26                 6546   \n",
      "\n",
      "        Costumer ID LabelEnc  Category LabelEnc  Sub-Category LabelEnc  \\\n",
      "Row ID                                                                   \n",
      "32298                   1286                  2                      0   \n",
      "26341                    808                  0                      5   \n",
      "25330                    336                  2                     13   \n",
      "13524                    873                  2                     13   \n",
      "47221                   1290                  2                      6   \n",
      "...                      ...                ...                    ...   \n",
      "24175                    383                  1                      3   \n",
      "29002                    854                  1                      8   \n",
      "35398                   1587                  1                      1   \n",
      "9596                    1249                  1                      3   \n",
      "6147                     981                  1                     12   \n",
      "\n",
      "        Discount LabelEnc  \n",
      "Row ID                     \n",
      "32298                   0  \n",
      "26341                   0  \n",
      "25330                   0  \n",
      "13524                   0  \n",
      "47221                   0  \n",
      "...                   ...  \n",
      "24175                   0  \n",
      "29002                   0  \n",
      "35398                   4  \n",
      "9596                    0  \n",
      "6147                    0  \n",
      "\n",
      "[51200 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Label encoding de algumas variáveis\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "if \"Category\" in data2:\n",
    "    process_Product_ID = True\n",
    "    process_Costumer_ID = True\n",
    "    process_Category = True\n",
    "    process_Sub_Category = True\n",
    "    process_Discount = True\n",
    "else: \n",
    "    process_Product_ID = False\n",
    "    process_Costumer_ID = False\n",
    "    process_Category = False\n",
    "    process_Sub_Category = False\n",
    "    process_Discount = False\n",
    "\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "if process_Product_ID:\n",
    "    data2[\"Product ID LabelEnc\"] = lb_make.fit_transform(data2[\"Product ID\"])\n",
    "\n",
    "if process_Costumer_ID:\n",
    "    data2[\"Costumer ID LabelEnc\"] = lb_make.fit_transform(data2[\"Customer ID\"])\n",
    "\n",
    "if process_Category:\n",
    "    data2[\"Category LabelEnc\"] = lb_make.fit_transform(data2[\"Category\"])\n",
    "\n",
    "if process_Sub_Category:\n",
    "    data2[\"Sub-Category LabelEnc\"] = lb_make.fit_transform(data2[\"Sub-Category\"])\n",
    "if process_Discount:\n",
    "    data2[\"Discount LabelEnc\"] = lb_make.fit_transform(data2[\"Discount\"])\n",
    "\n",
    "    \n",
    "if process_Product_ID: \n",
    "    data2 = data2.drop(['Product ID', 'Customer ID', \"Category\", \"Sub-Category\", \"Discount\"], axis=1)\n",
    "#from pandas.api.types import is_string_dtype\n",
    "\n",
    "if data2['Ship Mode'].dtype == 'category' or data2['Ship Mode'].dtype == 'object':\n",
    "   # print(\"Ship mode ainda está em categorias\")\n",
    "    #print(data2['Ship Mode'].unique())\n",
    "    ship_mode_dic = {'Same Day':1, 'First Class':2, 'Second Class':3,'Standard Class':4}\n",
    "    #dataTemp = pd.DataFrame({\"Ship Mode\": ship_mode_dic.keys()})\n",
    "    #print(\"Aqui vai\\n\")\n",
    "    data2[\"Ship Mode\"]= data2[\"Ship Mode\"].apply(lambda x: ship_mode_dic.get(x))\n",
    "    #print(data2)\n",
    "\n",
    "if \"Order_Priority\" in data2 and (data2['Order_Priority'].dtype == 'category' or data2['Order_Priority'].dtype == 'object'):\n",
    "    dataTemp = data2\n",
    "    # print(\"Ship mode ainda está em categorias\")\n",
    "    #print(dataTemp['Order_Priority'].unique())\n",
    "    priorities_dic = {'Critical':1, 'High':2, 'Medium':3,'Low':4}\n",
    "    #dataTemp = pd.DataFrame({\"Order_Priority\": priorities_dic.keys()})\n",
    "    #print(\"Aqui vai\\n\")\n",
    "    dataTemp[\"Order_Priority\"]= dataTemp[\"Order_Priority\"].apply(lambda x: priorities_dic.get(x))\n",
    "    #print(dataTemp.info())\n",
    "    data2 = dataTemp\n",
    "    \n",
    "print(\"\\nApós fazer Label Encoding\")\n",
    "print(data2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e383f3a1-2934-4ebe-bc11-fb9c0f1fe0be",
   "metadata": {},
   "source": [
    "### Neurónios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "097cb478-22be-4c57-8dd2-ee4117930d46",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Postal Code'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset_MLP \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOrder ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomer ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCustomer Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProduct ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProduct Name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPostal Code\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m dataset_MLP \u001b[38;5;241m=\u001b[39m dataset_MLP\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrder Priority\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarket\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSegment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShip Mode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShip Date\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset_MLP\u001b[38;5;241m.\u001b[39minfo())\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4806\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4815\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4816\u001b[0m ):\n\u001b[0;32m   4817\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4818\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4819\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4952\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6645\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Postal Code'] not found in axis\""
     ]
    }
   ],
   "source": [
    "dataset_MLP = dataset.drop(columns=['Order ID', 'Customer ID', 'Customer Name', 'Product ID', 'Product Name', 'Postal Code'])\n",
    "dataset_MLP = dataset_MLP.drop(['Order Priority', 'Market', \"City\", \"Segment\", \"Ship Mode\", \"Ship Date\"], axis=1)\n",
    "print(dataset_MLP.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a945d2-3161-4a80-aa10-251be0d9fbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "RANDOM_SEED = 2021\n",
    "\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44b207a7-b669-48dd-aa67-ce269d8dd30f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_MLP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_MLP \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_MLP\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfit\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m y_MLP \u001b[38;5;241m=\u001b[39m dataset_MLP[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfit\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_MLP\u001b[38;5;241m.\u001b[39minfo())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_MLP' is not defined"
     ]
    }
   ],
   "source": [
    "X_MLP = dataset_MLP.drop('Profit', axis=1)\n",
    "y_MLP = dataset_MLP[['Profit']]\n",
    "print(X_MLP.info())\n",
    "\n",
    "# Convert data\n",
    "if \"Order Date\" in X_MLP:\n",
    "    consider_year = True\n",
    "    consider_month = True\n",
    "    consider_day = True\n",
    "else: \n",
    "    consider_year = False\n",
    "    consider_month = False\n",
    "    consider_day = False\n",
    "    \n",
    "# Converter datas \n",
    "dates_order = DatetimeIndex(pd.to_datetime(X_MLP['Order Date'],format='%d-%m-%Y', errors='coerce'))\n",
    "if consider_year : \n",
    "    X_MLP['Year_order'] = dates_order.year\n",
    "    \n",
    "if consider_month : \n",
    "    X_MLP['Month_order'] = dates_order.month\n",
    "    \n",
    "if consider_day : \n",
    "    X_MLP['Day_order'] = dates_order.day\n",
    "    \n",
    "if 'Order Date' in X_MLP:\n",
    "    X_MLP = X_MLP.drop(['Order Date'], axis=1)\n",
    "#print(X)\n",
    "# Convert ID's to Label encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "if \"State\" in X_MLP:\n",
    "    list_to_process = [\"State\", \"Country\", \"Region\", \"Category\", \"Sub-Category\"]\n",
    "\n",
    "lb_make = LabelEncoder()\n",
    "\n",
    "if list_to_process:\n",
    "    for column in list_to_process:\n",
    "        X_MLP[column] = lb_make.fit_transform(X_MLP[column]) \n",
    "\n",
    "\n",
    "\n",
    "scaler_X = MinMaxScaler(feature_range=(0, 1)).fit(X_MLP)\n",
    "\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1)).fit(y_MLP)\n",
    "\n",
    "X_scaled = pd.DataFrame(scaler_X.transform(X_MLP[X_MLP.columns]), columns=X_MLP.columns)\n",
    "y_scaled = pd.DataFrame(scaler_y.transform(y_MLP[y_MLP.columns]), columns=y_MLP.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec623efb-eac3-4f70-85d3-93a9a428f470",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_scaled\u001b[38;5;241m=\u001b[39m\u001b[43mX_scaled\u001b[49m\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m y_scaled\u001b[38;5;241m=\u001b[39my_scaled\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_scaled, y_scaled, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mRANDOM_SEED)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "X_scaled=X_scaled.dropna().reset_index(drop=True)\n",
    "y_scaled=y_scaled.dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "number_columns = len(X_scaled.columns)#.count()\n",
    "#print(\"Número de colunas: \", number_columns)\n",
    "\n",
    "def build_model(activation='relu', learning_rate=0.01):\n",
    "#create a sequential model (with three Layers - Last one is the output)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(number_columns, input_dim=number_columns, activation=activation))\n",
    "    model.add(Dense(6, activation=activation))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "  \n",
    "     #compile the model\n",
    "    #Define the Loss function, the otimizer and metrics to be used\n",
    "    model. compile(\n",
    "        loss = 'mae',\n",
    "        optimizer = tf.optimizers.Adam(learning_rate),\n",
    "        metrics = ['mae', 'mse'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "TUNING_DICT = {\n",
    "    'activation' : ['relu', 'sigmoid'],\n",
    "    'learning_rate' : [0.01, 0.001]\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "model = KerasRegressor(build_fn=build_model, epochs=15,batch_size=number_columns)\n",
    "grid_search = GridSearchCV(estimator = model,\n",
    "                            param_grid = TUNING_DICT,\n",
    "                            cv = kf,\n",
    "                            scoring = 'neg_mean_absolute_error',\n",
    "                            refit ='True',\n",
    "                            verbose = 1)\n",
    "\n",
    "grid_search.fit(X_train, y_train, validation_split=0.2)\n",
    "\n",
    "\"\"\"\n",
    "def BuildModel():\n",
    "     model = Sequential()\n",
    "     model.add(Dense(128, input_dim=12,activation='relu')) \n",
    "     model.add(Dense(32, activation='relu')) \n",
    "     model.add(Dense(8,activation='relu')) \n",
    "     model.add(Dense(1,activation='linear'))\n",
    "     model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")   \n",
    "     return model\n",
    "\n",
    "BuildModel().summary()\n",
    "\n",
    "regressor = KerasRegressor(build_fn=BuildModel,epochs=20,batch_size=12)\n",
    "print(X_scaled)\n",
    "print(y_scaled)\n",
    "regressor.fit(X_scaled,y_scaled) \n",
    "\n",
    "y_pred = regressor.predict(X_scaled)\n",
    " \n",
    "\n",
    "mse_krr = mean_squared_error(y_scaled, y_pred)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f88aa5f0-3750-4740-9b15-346a15a56f8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Overfitting analisys\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Our best model (remember we set refit\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m best_mlp_model \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlivelossplot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PlotLossesKerasTF\n\u001b[0;32m      7\u001b[0m best_mlp_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m      8\u001b[0m validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test),\n\u001b[0;32m      9\u001b[0m callbacks\u001b[38;5;241m=\u001b[39m[PlotLossesKerasTF()], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_search' is not defined"
     ]
    }
   ],
   "source": [
    "# Overfitting analisys\n",
    "\n",
    "#Our best model (remember we set refit\n",
    "best_mlp_model = grid_search.best_estimator_\n",
    "\n",
    "from livelossplot import PlotLossesKerasTF\n",
    "best_mlp_model.fit(X_train, y_train, epochs=20,\n",
    "validation_data=(X_test, y_test),\n",
    "callbacks=[PlotLossesKerasTF()], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a25ad198-237d-4c9b-967f-01e32218b85f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_mlp_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#0btain predictions\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mbest_mlp_model\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mreshape(predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m predicions_unscaled \u001b[38;5;241m=\u001b[39m scaler_y\u001b[38;5;241m.\u001b[39minverse_transform(predictions)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_mlp_model' is not defined"
     ]
    }
   ],
   "source": [
    " #0btain predictions\n",
    "\n",
    "predictions = best_mlp_model.predict(X_test)\n",
    "\n",
    "predictions = predictions.reshape(predictions.shape[0], 1)\n",
    "predicions_unscaled = scaler_y.inverse_transform(predictions)\n",
    "predicions_unscaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d744c38e-6c44-45c4-b1e5-106c72871f53",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_test_unscaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler_y\u001b[49m\u001b[38;5;241m.\u001b[39minverse_transform(y_test)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Visualising the actual and predicted result\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreal_predicted_viz\u001b[39m(limit):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaler_y' is not defined"
     ]
    }
   ],
   "source": [
    "y_test_unscaled = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "#Visualising the actual and predicted result\n",
    "def real_predicted_viz(limit):\n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.plot(y_test_unscaled[:limit], color = 'green', label = 'Actual')\n",
    "    plt.plot (predicions_unscaled[:limit], color = 'red', label = 'Predicted')\n",
    "    plt.grid(alpha = 0.3)\n",
    "    plt.xlabel('I don`t know')\n",
    "    plt.ylabel ('Profit')\n",
    "    plt.title('Real vs Predicted')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "#let's Limit to 200 comparisions for better visualization\n",
    "real_predicted_viz(200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced79ae6-6b6c-45ab-be50-611519fbc0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Best: %f using %s\" % (grid_search.best_score_, grid_search.best_params_))\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
